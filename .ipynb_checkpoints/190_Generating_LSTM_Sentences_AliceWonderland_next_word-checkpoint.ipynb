{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i3SMFJYftfEs"
   },
   "source": [
    "# 190. Keras API 와 LSTM 을 이용한 이상한 나라의 Alice 문장 생성기\n",
    "\n",
    "- next word 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "asn1fHFytfEu"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.models import Sequential\n",
    "import tensorflow.keras.regularizers as regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "uP-mC7LTtfEx",
    "outputId": "764d0d6a-aff3-48ac-f14a-a60f1588f238"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from http://www.gutenberg.org/files/11/11.txt\n",
      "172032/167546 [==============================] - 0s 1us/step\n"
     ]
    }
   ],
   "source": [
    "path_to_file = tf.keras.utils.get_file('alice.txt', \"http://www.gutenberg.org/files/11/11.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "id": "SvrmXp25tfEz",
    "outputId": "84b4a642-2238-4a46-bd73-22be8abfc5b9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"project gutenberg's alice's adventures in wonderland, by lewis carroll this ebook is for the use of anyone anywhere at no cost and with almost no restrictions whatsoever.  you may copy it, give it away or re-use it under the terms of the project gutenberg license included with this ebook or online at www.gutenberg.org title: alice's adventures in wonderland author: lewis carroll posting date: june 25, 2008 [ebook #11] release date: march, 1994 [last updated: december 20, 2011] language: english character set encoding: ascii *** start of this project gutenberg ebook alice's adventures in wonderland *** alice's adventures in wonderland lewis carroll the millennium fulcrum edition 3.0 chapter i. down the rabbit-hole alice was beginning to get very tired of sitting by her sister on the bank, and of having nothing to do: once or twice she had peeped into the book her sister was reading, but it had no pictures or conversations in it, 'and what is the use of a book,' thought alice 'without pi\""
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = open(path_to_file)\n",
    "texts = r.readlines()\n",
    "lines = []\n",
    "\n",
    "for line in texts:\n",
    "    line = line.strip().lower()\n",
    "    if len(line) == 0:\n",
    "        continue\n",
    "    lines.append(line)\n",
    "\n",
    "text = \" \".join(lines)\n",
    "text[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1RuGgWAmtfE2"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "corpus = re.split('[,.]', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 216
    },
    "colab_type": "code",
    "id": "RyUJ7MxNtfE4",
    "outputId": "b0f264ae-dc89-4af0-e4c7-060f8b391b43"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"project gutenberg's alice's adventures in wonderland\",\n",
       " ' by lewis carroll this ebook is for the use of anyone anywhere at no cost and with almost no restrictions whatsoever',\n",
       " '  you may copy it',\n",
       " ' give it away or re-use it under the terms of the project gutenberg license included with this ebook or online at www',\n",
       " 'gutenberg',\n",
       " \"org title: alice's adventures in wonderland author: lewis carroll posting date: june 25\",\n",
       " ' 2008 [ebook #11] release date: march',\n",
       " ' 1994 [last updated: december 20',\n",
       " \" 2011] language: english character set encoding: ascii *** start of this project gutenberg ebook alice's adventures in wonderland *** alice's adventures in wonderland lewis carroll the millennium fulcrum edition 3\",\n",
       " '0 chapter i']"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "mRzxcEeatfE6",
    "outputId": "bb0e9624-6d92-44e9-bf53-457a17320754"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3338\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer()\n",
    "\n",
    "tokenizer.fit_on_texts(corpus)\n",
    "total_words = len(tokenizer.word_index) + 1\n",
    "print(total_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "rD29b-YrM8hJ",
    "outputId": "9629ed93-c696-464c-85fb-6c6fb7e5d7e0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(11, 'you'), (12, 'alice'), (13, 'was'), (14, 'i'), (15, 'that')]"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(tokenizer.index_word.items())[10:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "t4UF7YzUM8hO",
    "outputId": "082a6ca4-8cb2-412f-843f-7bbdd215ebdf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('you', 11), ('alice', 12), ('was', 13), ('i', 14), ('that', 15)]"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(tokenizer.word_index.items())[10:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AQlBVvwitfE8"
   },
   "outputs": [],
   "source": [
    "# token list 를 이용한 input sequence 생성\n",
    "input_sequences = []\n",
    "\n",
    "for line in corpus:\n",
    "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
    "    for i in range(1, len(token_list)):\n",
    "        n_gram_sequence = token_list[:i+1]\n",
    "        input_sequences.append(n_gram_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 214
    },
    "colab_type": "code",
    "id": "nI97Ln4atfE_",
    "outputId": "d7db6847-ff22-42d2-db62-2534f20e61f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27218\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[48, 1303],\n",
       " [48, 1303, 248],\n",
       " [48, 1303, 248, 342],\n",
       " [48, 1303, 248, 342, 10],\n",
       " [48, 1303, 248, 342, 10, 481],\n",
       " [59, 815],\n",
       " [59, 815, 816],\n",
       " [59, 815, 816, 22],\n",
       " [59, 815, 816, 22, 443],\n",
       " [59, 815, 816, 22, 443, 31]]"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(input_sequences))\n",
    "input_sequences[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "colab_type": "code",
    "id": "neKxP5KXtfFB",
    "outputId": "de76e840-2970-4898-c11a-153b074abe12"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0, ...,    0,   48, 1303],\n",
       "       [   0,    0,    0, ...,   48, 1303,  248],\n",
       "       [   0,    0,    0, ..., 1303,  248,  342],\n",
       "       ...,\n",
       "       [   0,    0,    0, ...,    4,  275,   40],\n",
       "       [   0,    0,    0, ...,  275,   40,  494],\n",
       "       [   0,    0,    0, ...,   40,  494,  621]], dtype=int32)"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pad sequences \n",
    "max_sequence_len = max([len(x) for x in input_sequences])\n",
    "\n",
    "input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n",
    "input_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ejnqC8LZtfFE"
   },
   "outputs": [],
   "source": [
    "text_dataset = tf.data.Dataset.from_tensor_slices(input_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "02XRjp6htfFH"
   },
   "outputs": [],
   "source": [
    "def split_input_target(chunk):\n",
    "    input_text = chunk[:-1]\n",
    "    target_text = chunk[-1]\n",
    "    return input_text, target_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 537
    },
    "colab_type": "code",
    "id": "CqJpy2c-tfFJ",
    "outputId": "444447ba-02c9-424b-bccd-12bd6bc4678a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[   0    0    0 ...    0    0   48]\n",
      " [   0    0    0 ...    0   48 1303]\n",
      " [   0    0    0 ...   48 1303  248]\n",
      " ...\n",
      " [   0    0    0 ...    8 1317    4]\n",
      " [   0    0    0 ... 1317    4   17]\n",
      " [   0    0    0 ...    4   17   15]], shape=(256, 62), dtype=int32)\n",
      "\n",
      "tf.Tensor(\n",
      "[1303  248  342   10  481  815  816   22  443   31   24    1  151    6\n",
      "  704 1006   19   49  817    3   18  482   49 1304 1305  175  343    8\n",
      "    8  169   27 1306  151    8  203    1  204    6    1   48   44  258\n",
      " 1007   18   22  443   27  818   19  625 1826  248  342   10  481 1827\n",
      "  815  816 1828  819 1829 1830  443  820 1832  819  136  140 1307 1834\n",
      " 1308 1836  550 1309  196 1837 1008 1009    6   22   48   44  443  248\n",
      "  342   10  481  248  342   10  481  815  816    1 1838 1839 1310  373\n",
      "  344   14    1  110  705   12   13  274    4  115   29  551    6  405\n",
      "   59   17  483   20    1 1010    6  406  154    4   45  148   27  706\n",
      "    7   23 1011   68    1  374   17  483   13  821    8   23   49  822\n",
      "   27 1311   10    8   38   31    1  151    6    5  374   62   12 1841\n",
      "  822   27 1311    2   28    7   13 1012   10   17  407  375   16  121\n",
      "   16    7   57    1  552  162  155   17  484   29  707    3 1013    1\n",
      " 1312    6  485    5 1842 1843   58   25  823    1  626    6  205   39\n",
      "    3 1313    1 1844  315    5  156  110   18 1845  163  259  316   59\n",
      "   17   13  154   28   29 1314   10   15 1315   74   12   91    8   28\n",
      "   29   93   35    6    1   76    4  275    1  110   95    4  295  170\n",
      "  206  170   14  188   25  627    2   60    7   62    8  122 1316 1317\n",
      "    4   17   15    7], shape=(256,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "dataset = text_dataset.map(split_input_target).batch(256, drop_remainder=True)\n",
    "\n",
    "for input, target in dataset.take(1):\n",
    "    print(input)\n",
    "    print()\n",
    "    print(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 393
    },
    "colab_type": "code",
    "id": "w9vH8Y59ajYL",
    "outputId": "c92ebbfc-e6a6-4abf-af67-803d28b18b92"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, None, 100)         333800    \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, None, 64)          34048     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, None, 64)          0         \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 16)                5184      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1669)              28373     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 3338)              5574460   \n",
      "=================================================================\n",
      "Total params: 5,975,865\n",
      "Trainable params: 5,975,865\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(total_words, 100))\n",
    "model.add(Bidirectional(LSTM(32, return_sequences = True)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(16))\n",
    "model.add(Dense(total_words/2, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(Dense(total_words, activation='softmax'))\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "AIg2f1HBxqof",
    "outputId": "040e3a96-7cbc-4a05-b690-3118e652a5e7",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "106/106 [==============================] - 2s 23ms/step - loss: 6.8967 - accuracy: 0.0617\n",
      "Epoch 2/150\n",
      "106/106 [==============================] - 2s 22ms/step - loss: 6.3009 - accuracy: 0.0622\n",
      "Epoch 3/150\n",
      "106/106 [==============================] - 2s 23ms/step - loss: 6.1763 - accuracy: 0.0622\n",
      "Epoch 4/150\n",
      "106/106 [==============================] - 2s 23ms/step - loss: 6.1326 - accuracy: 0.0624\n",
      "Epoch 5/150\n",
      "106/106 [==============================] - 2s 23ms/step - loss: 6.0668 - accuracy: 0.0654\n",
      "Epoch 6/150\n",
      "106/106 [==============================] - 2s 23ms/step - loss: 5.9735 - accuracy: 0.0682\n",
      "Epoch 7/150\n",
      "106/106 [==============================] - 2s 23ms/step - loss: 5.9037 - accuracy: 0.0723\n",
      "Epoch 8/150\n",
      "106/106 [==============================] - 2s 23ms/step - loss: 5.8529 - accuracy: 0.0754\n",
      "Epoch 9/150\n",
      "106/106 [==============================] - 2s 23ms/step - loss: 5.8032 - accuracy: 0.0763\n",
      "Epoch 10/150\n",
      "106/106 [==============================] - 2s 23ms/step - loss: 5.7410 - accuracy: 0.0808\n",
      "Epoch 11/150\n",
      "106/106 [==============================] - 2s 23ms/step - loss: 5.6718 - accuracy: 0.0848\n",
      "Epoch 12/150\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 5.5934 - accuracy: 0.0923\n",
      "Epoch 13/150\n",
      "106/106 [==============================] - 2s 23ms/step - loss: 5.5196 - accuracy: 0.0974\n",
      "Epoch 14/150\n",
      "106/106 [==============================] - 2s 23ms/step - loss: 5.4544 - accuracy: 0.1045\n",
      "Epoch 15/150\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 5.3965 - accuracy: 0.1112\n",
      "Epoch 16/150\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 5.3410 - accuracy: 0.1172\n",
      "Epoch 17/150\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 5.2936 - accuracy: 0.1218\n",
      "Epoch 18/150\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 5.2467 - accuracy: 0.1240\n",
      "Epoch 19/150\n",
      "106/106 [==============================] - 2s 23ms/step - loss: 5.2031 - accuracy: 0.1274\n",
      "Epoch 20/150\n",
      "106/106 [==============================] - 2s 23ms/step - loss: 5.1611 - accuracy: 0.1292\n",
      "Epoch 21/150\n",
      "106/106 [==============================] - 2s 23ms/step - loss: 5.1186 - accuracy: 0.1320\n",
      "Epoch 22/150\n",
      "106/106 [==============================] - 2s 23ms/step - loss: 5.0865 - accuracy: 0.1329\n",
      "Epoch 23/150\n",
      "106/106 [==============================] - 2s 23ms/step - loss: 5.0426 - accuracy: 0.1354\n",
      "Epoch 24/150\n",
      "106/106 [==============================] - 2s 23ms/step - loss: 5.0070 - accuracy: 0.1380\n",
      "Epoch 25/150\n",
      "106/106 [==============================] - 2s 22ms/step - loss: 4.9703 - accuracy: 0.1410\n",
      "Epoch 26/150\n",
      "106/106 [==============================] - 2s 22ms/step - loss: 4.9400 - accuracy: 0.1436\n",
      "Epoch 27/150\n",
      "106/106 [==============================] - 2s 22ms/step - loss: 4.9059 - accuracy: 0.1465\n",
      "Epoch 28/150\n",
      "106/106 [==============================] - 2s 23ms/step - loss: 4.8725 - accuracy: 0.1507\n",
      "Epoch 29/150\n",
      "106/106 [==============================] - 2s 22ms/step - loss: 4.8415 - accuracy: 0.1512\n",
      "Epoch 30/150\n",
      "106/106 [==============================] - 2s 23ms/step - loss: 4.8118 - accuracy: 0.1531\n",
      "Epoch 31/150\n",
      "106/106 [==============================] - 2s 23ms/step - loss: 4.7866 - accuracy: 0.1558\n",
      "Epoch 32/150\n",
      "106/106 [==============================] - 2s 23ms/step - loss: 4.7606 - accuracy: 0.1592\n",
      "Epoch 33/150\n",
      "106/106 [==============================] - 2s 23ms/step - loss: 4.7411 - accuracy: 0.1595\n",
      "Epoch 34/150\n",
      "106/106 [==============================] - 2s 23ms/step - loss: 4.7096 - accuracy: 0.1611\n",
      "Epoch 35/150\n",
      "106/106 [==============================] - 2s 23ms/step - loss: 4.6897 - accuracy: 0.1626\n",
      "Epoch 36/150\n",
      "106/106 [==============================] - 2s 23ms/step - loss: 4.6669 - accuracy: 0.1631\n",
      "Epoch 37/150\n",
      "106/106 [==============================] - 2s 23ms/step - loss: 4.6398 - accuracy: 0.1659\n",
      "Epoch 38/150\n",
      "106/106 [==============================] - 2s 23ms/step - loss: 4.6168 - accuracy: 0.1694\n",
      "Epoch 39/150\n",
      "106/106 [==============================] - 2s 23ms/step - loss: 4.5959 - accuracy: 0.1714\n",
      "Epoch 40/150\n",
      "106/106 [==============================] - 2s 22ms/step - loss: 4.5651 - accuracy: 0.1749\n",
      "Epoch 41/150\n",
      "106/106 [==============================] - 2s 23ms/step - loss: 4.5373 - accuracy: 0.1776\n",
      "Epoch 42/150\n",
      "106/106 [==============================] - 2s 23ms/step - loss: 4.5152 - accuracy: 0.1801\n",
      "Epoch 43/150\n",
      "106/106 [==============================] - 2s 22ms/step - loss: 4.4853 - accuracy: 0.1837\n",
      "Epoch 44/150\n",
      "106/106 [==============================] - 2s 23ms/step - loss: 4.4659 - accuracy: 0.1848\n",
      "Epoch 45/150\n",
      "106/106 [==============================] - 2s 23ms/step - loss: 4.4446 - accuracy: 0.1879\n",
      "Epoch 46/150\n",
      "106/106 [==============================] - 2s 23ms/step - loss: 4.4203 - accuracy: 0.1903\n",
      "Epoch 47/150\n",
      "106/106 [==============================] - 2s 23ms/step - loss: 4.4101 - accuracy: 0.1890\n",
      "Epoch 48/150\n",
      "106/106 [==============================] - 2s 23ms/step - loss: 4.3849 - accuracy: 0.1942\n",
      "Epoch 49/150\n",
      "106/106 [==============================] - 2s 23ms/step - loss: 4.3563 - accuracy: 0.1977\n",
      "Epoch 50/150\n",
      "106/106 [==============================] - 2s 23ms/step - loss: 4.3355 - accuracy: 0.1984\n",
      "Epoch 51/150\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 4.3229 - accuracy: 0.1976\n",
      "Epoch 52/150\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 4.3010 - accuracy: 0.2008\n",
      "Epoch 53/150\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 4.2811 - accuracy: 0.2061\n",
      "Epoch 54/150\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 4.2626 - accuracy: 0.2049\n",
      "Epoch 55/150\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 4.2615 - accuracy: 0.2045\n",
      "Epoch 56/150\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 4.2342 - accuracy: 0.2083\n",
      "Epoch 57/150\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 4.2143 - accuracy: 0.2077\n",
      "Epoch 58/150\n",
      "106/106 [==============================] - 2s 23ms/step - loss: 4.1902 - accuracy: 0.2127\n",
      "Epoch 59/150\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 4.1730 - accuracy: 0.2138\n",
      "Epoch 60/150\n",
      "106/106 [==============================] - 2s 23ms/step - loss: 4.1561 - accuracy: 0.2172\n",
      "Epoch 61/150\n",
      "106/106 [==============================] - 2s 23ms/step - loss: 4.1435 - accuracy: 0.2171\n",
      "Epoch 62/150\n",
      "106/106 [==============================] - 2s 23ms/step - loss: 4.1238 - accuracy: 0.2201\n",
      "Epoch 63/150\n",
      "106/106 [==============================] - 2s 23ms/step - loss: 4.1035 - accuracy: 0.2209\n",
      "Epoch 64/150\n",
      "106/106 [==============================] - 2s 23ms/step - loss: 4.0956 - accuracy: 0.2241\n",
      "Epoch 65/150\n",
      "106/106 [==============================] - 2s 23ms/step - loss: 4.0770 - accuracy: 0.2239\n",
      "Epoch 66/150\n",
      "106/106 [==============================] - 2s 23ms/step - loss: 4.0543 - accuracy: 0.2282\n",
      "Epoch 67/150\n",
      "106/106 [==============================] - 2s 23ms/step - loss: 4.0400 - accuracy: 0.2294\n",
      "Epoch 68/150\n",
      "106/106 [==============================] - 2s 22ms/step - loss: 4.0299 - accuracy: 0.2314\n",
      "Epoch 69/150\n",
      "106/106 [==============================] - 2s 23ms/step - loss: 4.0149 - accuracy: 0.2328\n",
      "Epoch 70/150\n",
      "106/106 [==============================] - 2s 23ms/step - loss: 4.0110 - accuracy: 0.2325\n",
      "Epoch 71/150\n",
      "106/106 [==============================] - 2s 23ms/step - loss: 3.9932 - accuracy: 0.2355\n",
      "Epoch 72/150\n",
      "106/106 [==============================] - 2s 22ms/step - loss: 3.9767 - accuracy: 0.2356\n",
      "Epoch 73/150\n",
      "106/106 [==============================] - 2s 23ms/step - loss: 3.9938 - accuracy: 0.2344\n",
      "Epoch 74/150\n",
      "106/106 [==============================] - 2s 23ms/step - loss: 3.9858 - accuracy: 0.2360\n",
      "Epoch 75/150\n",
      "106/106 [==============================] - 2s 23ms/step - loss: 3.9366 - accuracy: 0.2391\n",
      "Epoch 76/150\n",
      "106/106 [==============================] - 2s 23ms/step - loss: 3.9096 - accuracy: 0.2434\n",
      "Epoch 77/150\n",
      "106/106 [==============================] - 2s 23ms/step - loss: 3.8855 - accuracy: 0.2456\n",
      "Epoch 78/150\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 3.8757 - accuracy: 0.2469\n",
      "Epoch 79/150\n",
      "106/106 [==============================] - 2s 23ms/step - loss: 3.8630 - accuracy: 0.2485\n",
      "Epoch 80/150\n",
      "106/106 [==============================] - 2s 23ms/step - loss: 3.8444 - accuracy: 0.2496\n",
      "Epoch 81/150\n",
      "106/106 [==============================] - 2s 22ms/step - loss: 3.8311 - accuracy: 0.2504\n",
      "Epoch 82/150\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 3.8132 - accuracy: 0.2539\n",
      "Epoch 83/150\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 3.8018 - accuracy: 0.2558\n",
      "Epoch 84/150\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 3.7928 - accuracy: 0.2562\n",
      "Epoch 85/150\n",
      "106/106 [==============================] - 2s 23ms/step - loss: 3.7802 - accuracy: 0.2568\n",
      "Epoch 86/150\n",
      "106/106 [==============================] - 2s 23ms/step - loss: 3.7705 - accuracy: 0.2584\n",
      "Epoch 87/150\n",
      "106/106 [==============================] - 2s 23ms/step - loss: 3.7484 - accuracy: 0.2625\n",
      "Epoch 88/150\n",
      "106/106 [==============================] - 2s 23ms/step - loss: 3.7360 - accuracy: 0.2623\n",
      "Epoch 89/150\n",
      "106/106 [==============================] - 2s 23ms/step - loss: 3.7283 - accuracy: 0.2653\n",
      "Epoch 90/150\n",
      "106/106 [==============================] - 2s 23ms/step - loss: 3.7133 - accuracy: 0.2642\n",
      "Epoch 91/150\n",
      "106/106 [==============================] - 2s 23ms/step - loss: 3.7021 - accuracy: 0.2660\n",
      "Epoch 92/150\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 3.6963 - accuracy: 0.2687\n",
      "Epoch 93/150\n",
      "106/106 [==============================] - 2s 23ms/step - loss: 3.6772 - accuracy: 0.2708\n",
      "Epoch 94/150\n",
      "106/106 [==============================] - 2s 23ms/step - loss: 3.6599 - accuracy: 0.2730\n",
      "Epoch 95/150\n",
      "106/106 [==============================] - 2s 23ms/step - loss: 3.6508 - accuracy: 0.2738\n",
      "Epoch 96/150\n",
      "106/106 [==============================] - 2s 23ms/step - loss: 3.6302 - accuracy: 0.2754\n",
      "Epoch 97/150\n",
      "106/106 [==============================] - 2s 23ms/step - loss: 3.6202 - accuracy: 0.2773\n",
      "Epoch 98/150\n",
      "106/106 [==============================] - 2s 23ms/step - loss: 3.6071 - accuracy: 0.2783\n",
      "Epoch 99/150\n",
      "106/106 [==============================] - 2s 23ms/step - loss: 3.6024 - accuracy: 0.2797\n",
      "Epoch 100/150\n",
      "106/106 [==============================] - 2s 23ms/step - loss: 3.5820 - accuracy: 0.2822\n",
      "Epoch 101/150\n",
      "106/106 [==============================] - 2s 23ms/step - loss: 3.5694 - accuracy: 0.2850\n",
      "Epoch 102/150\n",
      "106/106 [==============================] - 2s 22ms/step - loss: 3.5628 - accuracy: 0.2840\n",
      "Epoch 103/150\n",
      "106/106 [==============================] - 2s 23ms/step - loss: 3.5604 - accuracy: 0.2863\n",
      "Epoch 104/150\n",
      "106/106 [==============================] - 2s 23ms/step - loss: 3.5493 - accuracy: 0.2859\n",
      "Epoch 105/150\n",
      "106/106 [==============================] - 2s 23ms/step - loss: 3.5340 - accuracy: 0.2904\n",
      "Epoch 106/150\n",
      "106/106 [==============================] - 2s 23ms/step - loss: 3.5114 - accuracy: 0.2912\n",
      "Epoch 107/150\n",
      "106/106 [==============================] - 2s 23ms/step - loss: 3.5087 - accuracy: 0.2924\n",
      "Epoch 108/150\n",
      "106/106 [==============================] - 2s 23ms/step - loss: 3.4956 - accuracy: 0.2941\n",
      "Epoch 109/150\n",
      "106/106 [==============================] - 2s 23ms/step - loss: 3.5419 - accuracy: 0.2884\n",
      "Epoch 110/150\n",
      "106/106 [==============================] - 2s 23ms/step - loss: 3.4966 - accuracy: 0.2943\n",
      "Epoch 111/150\n",
      "106/106 [==============================] - 2s 23ms/step - loss: 3.4703 - accuracy: 0.2990\n",
      "Epoch 112/150\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 3.4556 - accuracy: 0.3002\n",
      "Epoch 113/150\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 3.4492 - accuracy: 0.3002\n",
      "Epoch 114/150\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 3.4451 - accuracy: 0.3031\n",
      "Epoch 115/150\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 3.4175 - accuracy: 0.3081\n",
      "Epoch 116/150\n",
      "106/106 [==============================] - 2s 23ms/step - loss: 3.4073 - accuracy: 0.3079\n",
      "Epoch 117/150\n",
      "106/106 [==============================] - 2s 23ms/step - loss: 3.3958 - accuracy: 0.3103\n",
      "Epoch 118/150\n",
      "106/106 [==============================] - 2s 23ms/step - loss: 3.3805 - accuracy: 0.3128\n",
      "Epoch 119/150\n",
      "106/106 [==============================] - 2s 23ms/step - loss: 3.3748 - accuracy: 0.3143\n",
      "Epoch 120/150\n",
      "106/106 [==============================] - 2s 23ms/step - loss: 3.3595 - accuracy: 0.3151\n",
      "Epoch 121/150\n",
      "106/106 [==============================] - 2s 23ms/step - loss: 3.3509 - accuracy: 0.3166\n",
      "Epoch 122/150\n",
      "106/106 [==============================] - 2s 23ms/step - loss: 3.3465 - accuracy: 0.3183\n",
      "Epoch 123/150\n",
      "106/106 [==============================] - 2s 23ms/step - loss: 3.3321 - accuracy: 0.3229\n",
      "Epoch 124/150\n",
      "106/106 [==============================] - 2s 23ms/step - loss: 3.3240 - accuracy: 0.3224\n",
      "Epoch 125/150\n",
      "106/106 [==============================] - 2s 23ms/step - loss: 3.3327 - accuracy: 0.3201\n",
      "Epoch 126/150\n",
      "106/106 [==============================] - 2s 23ms/step - loss: 3.3118 - accuracy: 0.3219\n",
      "Epoch 127/150\n",
      "106/106 [==============================] - 2s 23ms/step - loss: 3.2950 - accuracy: 0.3242\n",
      "Epoch 128/150\n",
      "106/106 [==============================] - 2s 24ms/step - loss: 3.2919 - accuracy: 0.3241\n",
      "Epoch 129/150\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 3.2919 - accuracy: 0.3247\n",
      "Epoch 130/150\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 3.2749 - accuracy: 0.3268\n",
      "Epoch 131/150\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 3.2656 - accuracy: 0.3297\n",
      "Epoch 132/150\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 3.2507 - accuracy: 0.3315\n",
      "Epoch 133/150\n",
      "106/106 [==============================] - 2s 23ms/step - loss: 3.2405 - accuracy: 0.3323\n",
      "Epoch 134/150\n",
      "106/106 [==============================] - 2s 23ms/step - loss: 3.2235 - accuracy: 0.3367\n",
      "Epoch 135/150\n",
      "106/106 [==============================] - 2s 23ms/step - loss: 3.2177 - accuracy: 0.3387\n",
      "Epoch 136/150\n",
      "106/106 [==============================] - 2s 23ms/step - loss: 3.2540 - accuracy: 0.3334\n",
      "Epoch 137/150\n",
      "106/106 [==============================] - 2s 22ms/step - loss: 3.2352 - accuracy: 0.3360\n",
      "Epoch 138/150\n",
      "106/106 [==============================] - 2s 23ms/step - loss: 3.1949 - accuracy: 0.3436\n",
      "Epoch 139/150\n",
      "106/106 [==============================] - 2s 23ms/step - loss: 3.1742 - accuracy: 0.3447\n",
      "Epoch 140/150\n",
      "106/106 [==============================] - 2s 23ms/step - loss: 3.1643 - accuracy: 0.3504\n",
      "Epoch 141/150\n",
      "106/106 [==============================] - 2s 23ms/step - loss: 3.1618 - accuracy: 0.3476\n",
      "Epoch 142/150\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 3.1536 - accuracy: 0.3488\n",
      "Epoch 143/150\n",
      "106/106 [==============================] - 2s 23ms/step - loss: 3.1447 - accuracy: 0.3494\n",
      "Epoch 144/150\n",
      "106/106 [==============================] - 2s 23ms/step - loss: 3.1345 - accuracy: 0.3513\n",
      "Epoch 145/150\n",
      "106/106 [==============================] - 2s 23ms/step - loss: 3.1176 - accuracy: 0.3569\n",
      "Epoch 146/150\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 3.1157 - accuracy: 0.3528\n",
      "Epoch 147/150\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 3.1022 - accuracy: 0.3586\n",
      "Epoch 148/150\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 3.0959 - accuracy: 0.3597\n",
      "Epoch 149/150\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 3.0941 - accuracy: 0.3589\n",
      "Epoch 150/150\n",
      "106/106 [==============================] - 2s 23ms/step - loss: 3.0966 - accuracy: 0.3602\n",
      "CPU times: user 6min 51s, sys: 48.3 s, total: 7min 39s\n",
      "Wall time: 6min 23s\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(dataset, epochs=150, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "colab_type": "code",
    "id": "1fXTEO3GJ282",
    "outputId": "fd6ea4c8-960f-40a2-f19e-c5d1027793b5"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "acc = history.history['accuracy']\n",
    "loss = history.history['loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.figure(figsize=(12,4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs, acc, 'b', label='Training accuracy')\n",
    "plt.title('Training accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs, loss, 'b', label='Training Loss')\n",
    "plt.title('Training loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 109
    },
    "colab_type": "code",
    "id": "MPTokoLYxCvI",
    "outputId": "7630ba70-a924-4409-975e-41d4af6b2280"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-22-40c65ba3a64f>:7: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "Help me Obi Wan Kenobi, you're my only hope in the capital of rock the other passage was at the other state side of all a little sister's dream or angry 11 faces mournfully providing in a low voice state of receipt about a little thing would be beheaded or soup when the e evening grass fell at a little girl or 60 days of receipt as your history of the united states or hippopotamus on their slates and date gardeners instantly the white rabbit derive and or re others so that is to you ' said the king and and the jury were playing that look in a\n"
     ]
    }
   ],
   "source": [
    "seed_text = \"Help me Obi Wan Kenobi, you're my only hope\"\n",
    "next_words = 100\n",
    "\n",
    "for _ in range(next_words):\n",
    "    token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "    token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
    "    predicted = model.predict_classes(token_list, verbose=0)\n",
    "    output_word = tokenizer.index_word[predicted[0]]\n",
    "    seed_text += \" \" + output_word\n",
    "print(seed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AJzIYX4Fw574"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "190_Generating_LSTM_Sentences_AliceWonderland_next_word.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
