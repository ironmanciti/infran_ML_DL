{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ItXfxkxvosLH"
   },
   "source": [
    "# 케라스와 텐서플로 허브를 사용한 영화 리뷰 텍스트 분류하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "txOb1UvRgUWr"
   },
   "source": [
    "-  영화 리뷰(review) 텍스트를 *긍정*(positive) 또는 *부정*(negative)으로 분류. 이 예제는 *이진*(binary)-또는 클래스(class)가 두 개인- 분류 문제. \n",
    "\n",
    "\n",
    "-  텐서플로 허브(TensorFlow Hub)와 케라스(Keras)를 사용한 전이 학습(transfer learning) \n",
    "\n",
    "\n",
    "- [인터넷 영화 데이터베이스](https://www.imdb.com/)(Internet Movie Database)에서 수집한 50,000개의 영화 리뷰 텍스트를 담은 [IMDB 데이터셋](https://www.tensorflow.org/api_docs/python/tf/keras/datasets/imdb)을 사용. 25,000개 리뷰는 훈련용으로, 25,000개는 테스트용. 긍정적인 리뷰와 부정적인 리뷰의 개수는 동일(균형 잡힌 dataset).  \n",
    "\n",
    "- 레이블(label)은 정수 0 또는 1. 0은 부정적인 리뷰이고 1은 긍정적인 리뷰.\n",
    "\n",
    "\n",
    "- [tf.keras](https://www.tensorflow.org/guide/keras)와 전이 학습 라이브러리이자 플랫폼인 [텐서플로 허브](https://www.tensorflow.org/hub)를 사용 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2020-09-23T07:22:51.186418Z",
     "iopub.status.busy": "2020-09-23T07:22:51.185735Z",
     "iopub.status.idle": "2020-09-23T07:23:03.489107Z",
     "shell.execute_reply": "2020-09-23T07:23:03.488522Z"
    },
    "id": "2ew7HTbPpCJH",
    "outputId": "b96df5cf-a498-4b7c-c6ad-98c58ab76c9b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "버전:  2.4.1\n",
      "허브 버전:  0.12.0\n",
      "GPU 사용 가능\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "print(\"버전: \", tf.__version__)\n",
    "print(\"허브 버전: \", hub.__version__)\n",
    "print(\"GPU\", \"사용 가능\" if tf.config.experimental.list_physical_devices(\"GPU\") else \"사용 불가능\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iAsKG535pHep"
   },
   "source": [
    "## IMDB 데이터셋 다운로드\n",
    "\n",
    "- IMDB 데이터셋은 [imdb reviews](https://www.tensorflow.org/datasets/catalog/imdb_reviews) 또는 [텐서플로 데이터셋](https://www.tensorflow.org/datasets)(TensorFlow datasets)에 포함되어 있다. \n",
    "\n",
    "- 다음 코드는 IMDB 데이터셋을 컴퓨터(또는 Colab 런타임)에 다운로드."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-23T07:23:03.495101Z",
     "iopub.status.busy": "2020-09-23T07:23:03.494326Z",
     "iopub.status.idle": "2020-09-23T07:23:59.051101Z",
     "shell.execute_reply": "2020-09-23T07:23:59.050421Z"
    },
    "id": "zXXx5Oc3pOmN"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 25000)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data, test_data = tfds.load(\n",
    "    name=\"imdb_reviews\", \n",
    "    split=('train', 'test'),\n",
    "    as_supervised=True)\n",
    "\n",
    "len(train_data), len(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l50X3GfjpU4r"
   },
   "source": [
    "## 데이터 탐색\n",
    "\n",
    "처음 1개의 샘플을 출력해 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2020-09-23T07:23:59.056502Z",
     "iopub.status.busy": "2020-09-23T07:23:59.055796Z",
     "iopub.status.idle": "2020-09-23T07:23:59.102192Z",
     "shell.execute_reply": "2020-09-23T07:23:59.102749Z"
    },
    "id": "QtTS4kpEpjbi",
    "outputId": "38ac44c4-5eb9-41a2-8781-3dff58e5d91e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(1,), dtype=string, numpy=\n",
       " array([b\"This was an absolutely terrible movie. Don't be lured in by Christopher Walken or Michael Ironside. Both are great actors, but this must simply be their worst role in history. Even their great acting could not redeem this movie's ridiculous storyline. This movie is an early nineties US propaganda piece. The most pathetic scenes were those when the Columbian rebels were making their cases for revolutions. Maria Conchita Alonso appeared phony, and her pseudo-love affair with Walken was nothing but a pathetic emotional plug in a movie that was devoid of any real meaning. I am disappointed that there are movies like this, ruining actor's like Christopher Walken's good name. I could barely sit through it.\"],\n",
       "       dtype=object)>, <tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>)"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_examples_batch, train_labels_batch = next(iter(train_data.batch(1)))\n",
    "train_examples_batch, train_labels_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LLC02j2g-llC"
   },
   "source": [
    "## 모델 구성\n",
    "\n",
    "* 전이 학습의 장점을 이용하므로 텍스트 전처리에 대해 신경 쓸 필요 없다.\n",
    "* 임베딩은 고정 크기이기 때문에 처리 과정이 단순.\n",
    "\n",
    "[텐서플로 허브](https://www.tensorflow.org/hub)에 있는 **사전 훈련된 텍스트 임베딩 모델**인 [google/tf2-preview/gnews-swivel-20dim/1](https://tfhub.dev/google/tf2-preview/gnews-swivel-20dim/1)을 사용."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "In2nDpTLkgKa"
   },
   "source": [
    "- 문장을 임베딩시키기 위해 텐서플로 허브 모델을 사용하는 케라스 층을 작성하고 몇 개의 샘플을 입력하여 테스트\n",
    "\n",
    "\n",
    "- 입력 텍스트의 길이에 상관없이 임베딩의 출력 크기는 `(num_examples, embedding_dimension)`가 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2020-09-23T07:23:59.115136Z",
     "iopub.status.busy": "2020-09-23T07:23:59.114500Z",
     "iopub.status.idle": "2020-09-23T07:24:00.779807Z",
     "shell.execute_reply": "2020-09-23T07:24:00.779180Z"
    },
    "id": "_NUbzVeYkgcO",
    "outputId": "59ade9a0-0e5b-4337-8245-2a29367f5688"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x00000275C14CC9D0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x00000275C14CC9D0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x00000275BECCD5E0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x00000275BECCD5E0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x00000275C105B310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x00000275C105B310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 20), dtype=float32, numpy=\n",
       "array([[ 2.209591  , -2.7093675 ,  3.6802928 , -1.0291991 , -4.1671185 ,\n",
       "        -2.4566064 , -2.2519937 , -0.36589956,  1.9485804 , -3.1104462 ,\n",
       "        -2.4610963 ,  1.3139242 , -0.9161584 , -0.16625322, -3.723651  ,\n",
       "         1.8498232 ,  3.499562  , -1.2373022 , -2.8403084 , -1.213074  ]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding = \"https://tfhub.dev/google/tf2-preview/gnews-swivel-20dim/1\"\n",
    "\n",
    "hub_layer = hub.KerasLayer(embedding, input_shape=[], \n",
    "                           dtype=tf.string, trainable=True)\n",
    "\n",
    "hub_layer(train_examples_batch[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dfSbV6igl1EH"
   },
   "source": [
    "### 전체 모델 작성\n",
    "\n",
    "1. 첫 번째 층은 텐서플로 허브 층. 이 층은 사전 훈련된 모델을 사용하여 하나의 문장을 임베딩 벡터로 매핑.   \n",
    "    - 여기서 사용하는 사전 훈련된 텍스트 임베딩 모델([google/tf2-preview/gnews-swivel-20dim/1](https://tfhub.dev/google/tf2-preview/gnews-swivel-20dim/1))은 하나의 문장을 토큰(token)으로 나누고 각 토큰의 임베딩을 연결하여 반환\n",
    "    - 최종 차원은 `(num_examples, embedding_dimension)`\n",
    "    \n",
    "    \n",
    "2. 이 고정 크기의 출력 벡터는 16개의 은닉 유닛(hidden unit)을 가진 완전 연결 층(`Dense`)으로 주입된다.  \n",
    "\n",
    "\n",
    "3. 마지막 층은 하나의 출력 노드를 가진 완전 연결 층. `sigmoid` 활성화 함수를 사용하므로 확률 또는 신뢰도 수준을 표현하는 0~1 사이의 실수 출력."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2020-09-23T07:24:00.791800Z",
     "iopub.status.busy": "2020-09-23T07:24:00.791093Z",
     "iopub.status.idle": "2020-09-23T07:24:01.201917Z",
     "shell.execute_reply": "2020-09-23T07:24:01.202360Z"
    },
    "id": "xpKOoWgu-llD",
    "outputId": "6c56c793-7095-42b7-f8ec-eb9784a65e61"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "keras_layer_1 (KerasLayer)   (None, 20)                400020    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                336       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 400,373\n",
      "Trainable params: 400,373\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(hub_layer)\n",
    "model.add(tf.keras.layers.Dense(16, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(1))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L4EqVWg4-llM"
   },
   "source": [
    "### 손실 함수와 옵티마이저\n",
    "\n",
    "- 이진 분류 문제이고 모델이 확률을 출력하므로 `binary_crossentropy` 손실 함수를 사용."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-23T07:24:01.214922Z",
     "iopub.status.busy": "2020-09-23T07:24:01.214237Z",
     "iopub.status.idle": "2020-09-23T07:24:01.223564Z",
     "shell.execute_reply": "2020-09-23T07:24:01.224056Z"
    },
    "id": "Mr0GP-cQ-llN"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "35jv_fzP-llU"
   },
   "source": [
    "## 모델 훈련\n",
    "\n",
    "- 512개의 샘플로 이루어진 미니배치(mini-batch)에서 20번의 에포크(epoch) 동안 훈련  \n",
    "\n",
    "- 훈련하는 동안 10,000개의 검증 세트에서 모델의 손실과 정확도를 모니터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2020-09-23T07:24:01.228603Z",
     "iopub.status.busy": "2020-09-23T07:24:01.227977Z",
     "iopub.status.idle": "2020-09-23T07:24:42.288608Z",
     "shell.execute_reply": "2020-09-23T07:24:42.289071Z"
    },
    "id": "tXSGrjWZ-llW",
    "outputId": "f3f87b00-cffc-4493-ce2f-9cf12a5bd867",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "49/49 [==============================] - 6s 92ms/step - loss: 1.4974 - accuracy: 0.5129 - val_loss: 0.7251 - val_accuracy: 0.5515\n",
      "Epoch 2/20\n",
      "49/49 [==============================] - 5s 91ms/step - loss: 0.6968 - accuracy: 0.5701 - val_loss: 0.6695 - val_accuracy: 0.5821\n",
      "Epoch 3/20\n",
      "49/49 [==============================] - 5s 88ms/step - loss: 0.6434 - accuracy: 0.6011 - val_loss: 0.6183 - val_accuracy: 0.6202\n",
      "Epoch 4/20\n",
      "49/49 [==============================] - 5s 91ms/step - loss: 0.5880 - accuracy: 0.6516 - val_loss: 0.5596 - val_accuracy: 0.6804\n",
      "Epoch 5/20\n",
      "49/49 [==============================] - 5s 90ms/step - loss: 0.5269 - accuracy: 0.7123 - val_loss: 0.4975 - val_accuracy: 0.7405\n",
      "Epoch 6/20\n",
      "49/49 [==============================] - 5s 92ms/step - loss: 0.4561 - accuracy: 0.7752 - val_loss: 0.4456 - val_accuracy: 0.7763\n",
      "Epoch 7/20\n",
      "49/49 [==============================] - 5s 92ms/step - loss: 0.4048 - accuracy: 0.8105 - val_loss: 0.4037 - val_accuracy: 0.8064\n",
      "Epoch 8/20\n",
      "49/49 [==============================] - 5s 90ms/step - loss: 0.3589 - accuracy: 0.8446 - val_loss: 0.3724 - val_accuracy: 0.8255\n",
      "Epoch 9/20\n",
      "49/49 [==============================] - 5s 93ms/step - loss: 0.3195 - accuracy: 0.8645 - val_loss: 0.3512 - val_accuracy: 0.8318\n",
      "Epoch 10/20\n",
      "49/49 [==============================] - 5s 92ms/step - loss: 0.2933 - accuracy: 0.8743 - val_loss: 0.3315 - val_accuracy: 0.8528\n",
      "Epoch 11/20\n",
      "49/49 [==============================] - 5s 90ms/step - loss: 0.2689 - accuracy: 0.8882 - val_loss: 0.3188 - val_accuracy: 0.8570\n",
      "Epoch 12/20\n",
      "49/49 [==============================] - 5s 91ms/step - loss: 0.2491 - accuracy: 0.8984 - val_loss: 0.3113 - val_accuracy: 0.8571\n",
      "Epoch 13/20\n",
      "49/49 [==============================] - 5s 92ms/step - loss: 0.2327 - accuracy: 0.9060 - val_loss: 0.3025 - val_accuracy: 0.8643\n",
      "Epoch 14/20\n",
      "49/49 [==============================] - 5s 90ms/step - loss: 0.2107 - accuracy: 0.9162 - val_loss: 0.3032 - val_accuracy: 0.8600\n",
      "Epoch 15/20\n",
      "49/49 [==============================] - 5s 92ms/step - loss: 0.2059 - accuracy: 0.9200 - val_loss: 0.2986 - val_accuracy: 0.8631\n",
      "Epoch 16/20\n",
      "49/49 [==============================] - 5s 90ms/step - loss: 0.1900 - accuracy: 0.9272 - val_loss: 0.2936 - val_accuracy: 0.8703\n",
      "Epoch 17/20\n",
      "49/49 [==============================] - 5s 91ms/step - loss: 0.1817 - accuracy: 0.9314 - val_loss: 0.2936 - val_accuracy: 0.8717\n",
      "Epoch 18/20\n",
      "49/49 [==============================] - 5s 91ms/step - loss: 0.1656 - accuracy: 0.9392 - val_loss: 0.2947 - val_accuracy: 0.8744\n",
      "Epoch 19/20\n",
      "49/49 [==============================] - 5s 93ms/step - loss: 0.1630 - accuracy: 0.9401 - val_loss: 0.2963 - val_accuracy: 0.8740\n",
      "Epoch 20/20\n",
      "49/49 [==============================] - 5s 89ms/step - loss: 0.1513 - accuracy: 0.9456 - val_loss: 0.2997 - val_accuracy: 0.8709\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_data.shuffle(10000).batch(512),\n",
    "                    epochs=20,\n",
    "                    validation_data=test_data.batch(512),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9EEGuDVuzb5r"
   },
   "source": [
    "## 모델 평가\n",
    "\n",
    "- 손실과 정확도 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2020-09-23T07:24:42.295104Z",
     "iopub.status.busy": "2020-09-23T07:24:42.294434Z",
     "iopub.status.idle": "2020-09-23T07:24:43.826214Z",
     "shell.execute_reply": "2020-09-23T07:24:43.825673Z"
    },
    "id": "zOMKywn4zReN",
    "outputId": "c6d2fd9a-4476-4d7e-db1c-b5968073815c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.300\n",
      "accuracy: 0.871\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(test_data.batch(512), verbose=0)\n",
    "\n",
    "for name, value in zip(model.metrics_names, results):\n",
    "  print(\"%s: %.3f\" % (name, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "ax1.plot(history.history['accuracy'])\n",
    "ax1.plot(history.history['val_accuracy'])\n",
    "ax1.set_xlabel('Epochs')\n",
    "ax1.set_ylabel('accuracy')\n",
    "ax1.legend(['accuarcy', 'val_accuracy'])\n",
    "\n",
    "ax2.plot(history.history['loss'])\n",
    "ax2.plot(history.history['val_loss'])\n",
    "ax2.set_xlabel('Epochs')\n",
    "ax2.set_ylabel('loss')\n",
    "ax2.legend(['loss', 'val_loss'])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "185_text_classification_with_hub.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
