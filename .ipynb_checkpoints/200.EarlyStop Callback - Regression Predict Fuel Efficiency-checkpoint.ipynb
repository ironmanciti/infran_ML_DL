{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 200. Early Stopping / Callback /Weight Load\n",
    "\n",
    "## Regression model - 자동차 연비 예측\n",
    "\n",
    "### UCI Machine Learning Repository 의 Auto MPG dataset 을 사용하여 Regression 예측 model 작성\n",
    "\n",
    "auto-mpg.data - data file  \n",
    "auto-mpg.names - data 설명 file\n",
    "\n",
    "1. mpg:           continuous  \n",
    "2. cylinders:     multi-valued discrete  \n",
    "3. displacement:  continuous (배기량)   \n",
    "4. horsepower:    continuous  \n",
    "5. weight:        continuous  \n",
    "6. acceleration:  continuous  \n",
    "7. model year:    multi-valued discrete  \n",
    "8. origin:        multi-valued discrete, 1 - USA, 2 - Europe, 3 - Japan  \n",
    "9. car name:      string (unique for each instance)  \n",
    "\n",
    "Missing Attribute Values:  horsepower has 6 missing values  ==> \"?\" 로 들어 있으므로 read_csv 시 nan 으로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dataset download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data\n",
      "32768/30286 [================================] - 0s 4us/step\n"
     ]
    }
   ],
   "source": [
    "data_path = keras.utils.get_file(\"auto-mpg.data\", \n",
    "                \"https://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['연비', '기통', '배기량', '마력', '무게', '가속력', '모델연도', '생산국']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>연비</th>\n",
       "      <th>기통</th>\n",
       "      <th>배기량</th>\n",
       "      <th>마력</th>\n",
       "      <th>무게</th>\n",
       "      <th>가속력</th>\n",
       "      <th>모델연도</th>\n",
       "      <th>생산국</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>307.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>3504.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.0</td>\n",
       "      <td>8</td>\n",
       "      <td>350.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>3693.0</td>\n",
       "      <td>11.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>318.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3436.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.0</td>\n",
       "      <td>8</td>\n",
       "      <td>304.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3433.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.0</td>\n",
       "      <td>8</td>\n",
       "      <td>302.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>3449.0</td>\n",
       "      <td>10.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     연비  기통    배기량     마력      무게   가속력  모델연도  생산국\n",
       "0  18.0   8  307.0  130.0  3504.0  12.0    70    1\n",
       "1  15.0   8  350.0  165.0  3693.0  11.5    70    1\n",
       "2  18.0   8  318.0  150.0  3436.0  11.0    70    1\n",
       "3  16.0   8  304.0  150.0  3433.0  12.0    70    1\n",
       "4  17.0   8  302.0  140.0  3449.0  10.5    70    1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv(data_path, names=column_names, na_values=\"?\", comment=\"\\t\", sep=\" \", skipinitialspace=True )\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>연비</th>\n",
       "      <th>기통</th>\n",
       "      <th>배기량</th>\n",
       "      <th>마력</th>\n",
       "      <th>무게</th>\n",
       "      <th>가속력</th>\n",
       "      <th>모델연도</th>\n",
       "      <th>생산국_1</th>\n",
       "      <th>생산국_2</th>\n",
       "      <th>생산국_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>307.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>3504.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.0</td>\n",
       "      <td>8</td>\n",
       "      <td>350.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>3693.0</td>\n",
       "      <td>11.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>318.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3436.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.0</td>\n",
       "      <td>8</td>\n",
       "      <td>304.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3433.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.0</td>\n",
       "      <td>8</td>\n",
       "      <td>302.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>3449.0</td>\n",
       "      <td>10.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     연비  기통    배기량     마력      무게   가속력  모델연도  생산국_1  생산국_2  생산국_3\n",
       "0  18.0   8  307.0  130.0  3504.0  12.0    70      1      0      0\n",
       "1  15.0   8  350.0  165.0  3693.0  11.5    70      1      0      0\n",
       "2  18.0   8  318.0  150.0  3436.0  11.0    70      1      0      0\n",
       "3  16.0   8  304.0  150.0  3433.0  12.0    70      1      0      0\n",
       "4  17.0   8  302.0  140.0  3449.0  10.5    70      1      0      0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.get_dummies(dataset, columns=[\"생산국\"])\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = dataset.pop('연비')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train, test 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(294, 9)\n",
      "(98, 9)\n",
      "(294,)\n",
      "(98,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(dataset.values, label.values)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train)).shuffle(10000).batch(32)\n",
    "test_ds  = tf.data.Dataset.from_tensor_slices((X_test, y_test)).batch(32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, activation=\"relu\", input_shape=(9,)))\n",
    "    model.add(Dense(64, activation=\"relu\"))\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    model.compile(loss='mse', optimizer='adam', metrics=['mse'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model\n",
    "\n",
    "1000 epoch 을 수행하고 training 과 validation accuarcy 를 history object 에 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 572.6559 - mse: 572.6559 - val_loss: 604.9678 - val_mse: 604.9678\n",
      "Epoch 2/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 530.7222 - mse: 530.7222 - val_loss: 552.0001 - val_mse: 552.0001\n",
      "Epoch 3/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 481.3267 - mse: 481.3267 - val_loss: 487.3341 - val_mse: 487.3341\n",
      "Epoch 4/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 418.3651 - mse: 418.3651 - val_loss: 407.3263 - val_mse: 407.3263\n",
      "Epoch 5/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 342.9168 - mse: 342.9168 - val_loss: 311.1405 - val_mse: 311.1405\n",
      "Epoch 6/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 257.9898 - mse: 257.9898 - val_loss: 211.9853 - val_mse: 211.9853\n",
      "Epoch 7/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 174.0455 - mse: 174.0455 - val_loss: 128.5548 - val_mse: 128.5548\n",
      "Epoch 8/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 109.0269 - mse: 109.0269 - val_loss: 77.0376 - val_mse: 77.0376\n",
      "Epoch 9/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 71.6021 - mse: 71.6021 - val_loss: 56.6063 - val_mse: 56.6063\n",
      "Epoch 10/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 53.7715 - mse: 53.7715 - val_loss: 48.9599 - val_mse: 48.9599\n",
      "Epoch 11/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 44.0577 - mse: 44.0577 - val_loss: 41.9840 - val_mse: 41.9840\n",
      "Epoch 12/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 35.5218 - mse: 35.5218 - val_loss: 35.6730 - val_mse: 35.6730\n",
      "Epoch 13/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 28.6440 - mse: 28.6440 - val_loss: 31.2625 - val_mse: 31.2625\n",
      "Epoch 14/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 23.5959 - mse: 23.5959 - val_loss: 28.1152 - val_mse: 28.1152\n",
      "Epoch 15/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 20.0648 - mse: 20.0648 - val_loss: 26.1908 - val_mse: 26.1908\n",
      "Epoch 16/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 17.3910 - mse: 17.3910 - val_loss: 24.7878 - val_mse: 24.7878\n",
      "Epoch 17/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 15.5812 - mse: 15.5812 - val_loss: 23.3460 - val_mse: 23.3460\n",
      "Epoch 18/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 14.2841 - mse: 14.2841 - val_loss: 21.9622 - val_mse: 21.9622\n",
      "Epoch 19/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 13.0632 - mse: 13.0632 - val_loss: 20.6561 - val_mse: 20.6561\n",
      "Epoch 20/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 12.2325 - mse: 12.2325 - val_loss: 19.5193 - val_mse: 19.5193\n",
      "Epoch 21/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 11.5574 - mse: 11.5574 - val_loss: 18.8384 - val_mse: 18.8384\n",
      "Epoch 22/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 11.0403 - mse: 11.0403 - val_loss: 17.9350 - val_mse: 17.9350\n",
      "Epoch 23/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 10.5207 - mse: 10.5207 - val_loss: 17.2408 - val_mse: 17.2408\n",
      "Epoch 24/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 10.0511 - mse: 10.0511 - val_loss: 16.8399 - val_mse: 16.8399\n",
      "Epoch 25/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 9.6707 - mse: 9.6707 - val_loss: 16.1277 - val_mse: 16.1277\n",
      "Epoch 26/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 9.3527 - mse: 9.3527 - val_loss: 15.6658 - val_mse: 15.6658\n",
      "Epoch 27/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 9.0417 - mse: 9.0417 - val_loss: 15.0563 - val_mse: 15.0563\n",
      "Epoch 28/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 8.8926 - mse: 8.8926 - val_loss: 14.4798 - val_mse: 14.4798\n",
      "Epoch 29/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 8.6619 - mse: 8.6619 - val_loss: 14.3902 - val_mse: 14.3902\n",
      "Epoch 30/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 8.4625 - mse: 8.4625 - val_loss: 14.1646 - val_mse: 14.1646\n",
      "Epoch 31/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 8.3272 - mse: 8.3272 - val_loss: 14.1433 - val_mse: 14.1433\n",
      "Epoch 32/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 8.1652 - mse: 8.1652 - val_loss: 14.0026 - val_mse: 14.0026\n",
      "Epoch 33/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 8.0314 - mse: 8.0314 - val_loss: 13.8750 - val_mse: 13.8750\n",
      "Epoch 34/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 7.9288 - mse: 7.9288 - val_loss: 13.6704 - val_mse: 13.6704\n",
      "Epoch 35/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7.8174 - mse: 7.8174 - val_loss: 13.7340 - val_mse: 13.7340\n",
      "Epoch 36/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 7.7336 - mse: 7.7336 - val_loss: 13.5778 - val_mse: 13.5778\n",
      "Epoch 37/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 7.6538 - mse: 7.6538 - val_loss: 13.2754 - val_mse: 13.2754\n",
      "Epoch 38/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 7.5462 - mse: 7.5462 - val_loss: 13.0933 - val_mse: 13.0933\n",
      "Epoch 39/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 7.4762 - mse: 7.4762 - val_loss: 13.0116 - val_mse: 13.0116\n",
      "Epoch 40/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7.4247 - mse: 7.4247 - val_loss: 12.7272 - val_mse: 12.7272\n",
      "Epoch 41/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 7.3170 - mse: 7.3170 - val_loss: 12.7434 - val_mse: 12.7434\n",
      "Epoch 42/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 7.2939 - mse: 7.2939 - val_loss: 12.7819 - val_mse: 12.7819\n",
      "Epoch 43/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7.2231 - mse: 7.2231 - val_loss: 12.7842 - val_mse: 12.7842\n",
      "Epoch 44/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7.1506 - mse: 7.1506 - val_loss: 12.5681 - val_mse: 12.5681\n",
      "Epoch 45/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7.1384 - mse: 7.1384 - val_loss: 12.5291 - val_mse: 12.5291\n",
      "Epoch 46/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7.0115 - mse: 7.0115 - val_loss: 12.5607 - val_mse: 12.5607\n",
      "Epoch 47/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6.9311 - mse: 6.9311 - val_loss: 12.4099 - val_mse: 12.4099\n",
      "Epoch 48/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6.9122 - mse: 6.9122 - val_loss: 12.3328 - val_mse: 12.3328\n",
      "Epoch 49/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6.8404 - mse: 6.8404 - val_loss: 12.3048 - val_mse: 12.3048\n",
      "Epoch 50/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6.8173 - mse: 6.8173 - val_loss: 12.3890 - val_mse: 12.3890\n",
      "Epoch 51/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6.7799 - mse: 6.7799 - val_loss: 12.4191 - val_mse: 12.4191\n",
      "Epoch 52/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6.7440 - mse: 6.7440 - val_loss: 12.1345 - val_mse: 12.1345\n",
      "Epoch 53/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6.6864 - mse: 6.6864 - val_loss: 12.1398 - val_mse: 12.1398\n",
      "Epoch 54/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6.6797 - mse: 6.6797 - val_loss: 11.9574 - val_mse: 11.9574\n",
      "Epoch 55/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6.6414 - mse: 6.6414 - val_loss: 12.1753 - val_mse: 12.1753\n",
      "Epoch 56/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6.6048 - mse: 6.6048 - val_loss: 11.8681 - val_mse: 11.8681\n",
      "Epoch 57/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6.5540 - mse: 6.5540 - val_loss: 11.8104 - val_mse: 11.8104\n",
      "Epoch 58/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6.5498 - mse: 6.5498 - val_loss: 11.9962 - val_mse: 11.9962\n",
      "Epoch 59/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6.4731 - mse: 6.4731 - val_loss: 11.5420 - val_mse: 11.5420\n",
      "Epoch 60/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6.4645 - mse: 6.4645 - val_loss: 11.4593 - val_mse: 11.4593\n",
      "Epoch 61/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6.4388 - mse: 6.4388 - val_loss: 11.5350 - val_mse: 11.5350\n",
      "Epoch 62/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6.3569 - mse: 6.3569 - val_loss: 11.6600 - val_mse: 11.6600\n",
      "Epoch 63/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 6.3617 - mse: 6.3617 - val_loss: 11.8939 - val_mse: 11.8939\n",
      "Epoch 64/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6.3496 - mse: 6.3496 - val_loss: 11.5407 - val_mse: 11.5407\n",
      "Epoch 65/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6.3162 - mse: 6.3162 - val_loss: 11.4044 - val_mse: 11.4044\n",
      "Epoch 66/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6.3141 - mse: 6.3141 - val_loss: 11.7967 - val_mse: 11.7967\n",
      "Epoch 67/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6.2964 - mse: 6.2964 - val_loss: 11.4328 - val_mse: 11.4328\n",
      "Epoch 68/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6.2746 - mse: 6.2746 - val_loss: 11.7383 - val_mse: 11.7383\n",
      "Epoch 69/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6.2441 - mse: 6.2441 - val_loss: 11.4676 - val_mse: 11.4676\n",
      "Epoch 70/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6.1908 - mse: 6.1908 - val_loss: 11.5201 - val_mse: 11.5201\n",
      "Epoch 71/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6.1911 - mse: 6.1911 - val_loss: 11.5426 - val_mse: 11.5426\n",
      "Epoch 72/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6.2106 - mse: 6.2106 - val_loss: 11.3049 - val_mse: 11.3049\n",
      "Epoch 73/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6.1605 - mse: 6.1605 - val_loss: 11.4561 - val_mse: 11.4561\n",
      "Epoch 74/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6.0960 - mse: 6.0960 - val_loss: 11.2468 - val_mse: 11.2468\n",
      "Epoch 75/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6.1019 - mse: 6.1019 - val_loss: 11.4378 - val_mse: 11.4378\n",
      "Epoch 76/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6.0472 - mse: 6.0472 - val_loss: 11.4190 - val_mse: 11.4190\n",
      "Epoch 77/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 6.0604 - mse: 6.0604 - val_loss: 11.3062 - val_mse: 11.3062\n",
      "Epoch 78/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6.0758 - mse: 6.0758 - val_loss: 11.2881 - val_mse: 11.2881\n",
      "Epoch 79/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6.0456 - mse: 6.0456 - val_loss: 11.3210 - val_mse: 11.3210\n",
      "Epoch 80/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6.0111 - mse: 6.0111 - val_loss: 11.3837 - val_mse: 11.3837\n",
      "Epoch 81/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 6.0666 - mse: 6.0666 - val_loss: 11.4336 - val_mse: 11.4336\n",
      "Epoch 82/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 6.0286 - mse: 6.0286 - val_loss: 11.1000 - val_mse: 11.1000\n",
      "Epoch 83/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 6.0146 - mse: 6.0146 - val_loss: 11.2648 - val_mse: 11.2648\n",
      "Epoch 84/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6.0311 - mse: 6.0311 - val_loss: 11.2174 - val_mse: 11.2174\n",
      "Epoch 85/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.9992 - mse: 5.9992 - val_loss: 11.2272 - val_mse: 11.2272\n",
      "Epoch 86/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6.0551 - mse: 6.0551 - val_loss: 11.7848 - val_mse: 11.7848\n",
      "Epoch 87/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6.0493 - mse: 6.0493 - val_loss: 11.1955 - val_mse: 11.1955\n",
      "Epoch 88/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 5.8732 - mse: 5.8732 - val_loss: 11.2780 - val_mse: 11.2780\n",
      "Epoch 89/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.9292 - mse: 5.9292 - val_loss: 11.0618 - val_mse: 11.0618\n",
      "Epoch 90/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 5.8913 - mse: 5.8913 - val_loss: 11.2044 - val_mse: 11.2044\n",
      "Epoch 91/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.8414 - mse: 5.8414 - val_loss: 11.7204 - val_mse: 11.7204\n",
      "Epoch 92/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 5.8904 - mse: 5.8904 - val_loss: 11.4031 - val_mse: 11.4031\n",
      "Epoch 93/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.8243 - mse: 5.8243 - val_loss: 11.5514 - val_mse: 11.5514\n",
      "Epoch 94/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 5.7874 - mse: 5.7874 - val_loss: 11.2015 - val_mse: 11.2015\n",
      "Epoch 95/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 5.7838 - mse: 5.7838 - val_loss: 11.1884 - val_mse: 11.1884\n",
      "Epoch 96/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 5.7692 - mse: 5.7692 - val_loss: 11.3933 - val_mse: 11.3933\n",
      "Epoch 97/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 5.7626 - mse: 5.7626 - val_loss: 11.2860 - val_mse: 11.2860\n",
      "Epoch 98/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 5.8634 - mse: 5.8634 - val_loss: 11.1392 - val_mse: 11.1392\n",
      "Epoch 99/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 5.7761 - mse: 5.7761 - val_loss: 11.6843 - val_mse: 11.6843\n",
      "Epoch 100/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.7321 - mse: 5.7321 - val_loss: 10.9951 - val_mse: 10.9951\n",
      "Epoch 101/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.7597 - mse: 5.7597 - val_loss: 11.1762 - val_mse: 11.1762\n",
      "Epoch 102/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.6944 - mse: 5.6944 - val_loss: 10.9934 - val_mse: 10.9934\n",
      "Epoch 103/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.6593 - mse: 5.6593 - val_loss: 11.2226 - val_mse: 11.2226\n",
      "Epoch 104/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 5.7042 - mse: 5.7042 - val_loss: 11.2582 - val_mse: 11.2582\n",
      "Epoch 105/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.6586 - mse: 5.6586 - val_loss: 11.0679 - val_mse: 11.0679\n",
      "Epoch 106/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.7032 - mse: 5.7032 - val_loss: 11.0023 - val_mse: 11.0023\n",
      "Epoch 107/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.6664 - mse: 5.6664 - val_loss: 10.6485 - val_mse: 10.6485\n",
      "Epoch 108/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.6572 - mse: 5.6572 - val_loss: 10.6618 - val_mse: 10.6618\n",
      "Epoch 109/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 5.6452 - mse: 5.6452 - val_loss: 10.9903 - val_mse: 10.9903\n",
      "Epoch 110/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.6636 - mse: 5.6636 - val_loss: 10.8460 - val_mse: 10.8460\n",
      "Epoch 111/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.6240 - mse: 5.6240 - val_loss: 11.0357 - val_mse: 11.0357\n",
      "Epoch 112/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.5714 - mse: 5.5714 - val_loss: 10.9079 - val_mse: 10.9079\n",
      "Epoch 113/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.5815 - mse: 5.5815 - val_loss: 10.9729 - val_mse: 10.9729\n",
      "Epoch 114/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.6004 - mse: 5.6004 - val_loss: 10.7114 - val_mse: 10.7114\n",
      "Epoch 115/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.6824 - mse: 5.6824 - val_loss: 10.5071 - val_mse: 10.5071\n",
      "Epoch 116/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.6262 - mse: 5.6262 - val_loss: 11.0208 - val_mse: 11.0208\n",
      "Epoch 117/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.5501 - mse: 5.5501 - val_loss: 10.7509 - val_mse: 10.7509\n",
      "Epoch 118/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.5298 - mse: 5.5298 - val_loss: 10.9101 - val_mse: 10.9101\n",
      "Epoch 119/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 5.5592 - mse: 5.5592 - val_loss: 10.8834 - val_mse: 10.8834\n",
      "Epoch 120/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 5.5156 - mse: 5.5156 - val_loss: 10.7641 - val_mse: 10.7641\n",
      "Epoch 121/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.5345 - mse: 5.5345 - val_loss: 10.6067 - val_mse: 10.6067\n",
      "Epoch 122/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 1ms/step - loss: 5.4505 - mse: 5.4505 - val_loss: 11.1811 - val_mse: 11.1811\n",
      "Epoch 123/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.5260 - mse: 5.5260 - val_loss: 11.0017 - val_mse: 11.0017\n",
      "Epoch 124/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.4826 - mse: 5.4826 - val_loss: 10.7389 - val_mse: 10.7389\n",
      "Epoch 125/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.4695 - mse: 5.4695 - val_loss: 10.7192 - val_mse: 10.7192\n",
      "Epoch 126/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.4511 - mse: 5.4511 - val_loss: 10.7810 - val_mse: 10.7810\n",
      "Epoch 127/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 5.5531 - mse: 5.5531 - val_loss: 10.9656 - val_mse: 10.9656\n",
      "Epoch 128/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 5.4615 - mse: 5.4615 - val_loss: 10.6934 - val_mse: 10.6934\n",
      "Epoch 129/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.4221 - mse: 5.4221 - val_loss: 11.1600 - val_mse: 11.1600\n",
      "Epoch 130/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.3967 - mse: 5.3967 - val_loss: 11.1672 - val_mse: 11.1672\n",
      "Epoch 131/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.4301 - mse: 5.4301 - val_loss: 10.8156 - val_mse: 10.8156\n",
      "Epoch 132/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.5248 - mse: 5.5248 - val_loss: 10.5335 - val_mse: 10.5335\n",
      "Epoch 133/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.4110 - mse: 5.4110 - val_loss: 10.6258 - val_mse: 10.6258\n",
      "Epoch 134/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 5.3640 - mse: 5.3640 - val_loss: 10.7419 - val_mse: 10.7419\n",
      "Epoch 135/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.3785 - mse: 5.3785 - val_loss: 10.8606 - val_mse: 10.8606\n",
      "Epoch 136/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.3664 - mse: 5.3664 - val_loss: 10.6100 - val_mse: 10.6100\n",
      "Epoch 137/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.3563 - mse: 5.3563 - val_loss: 10.8531 - val_mse: 10.8531\n",
      "Epoch 138/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.3102 - mse: 5.3102 - val_loss: 10.5816 - val_mse: 10.5816\n",
      "Epoch 139/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 5.3019 - mse: 5.3019 - val_loss: 10.4309 - val_mse: 10.4309\n",
      "Epoch 140/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 5.3097 - mse: 5.3097 - val_loss: 10.5175 - val_mse: 10.5175\n",
      "Epoch 141/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.3229 - mse: 5.3229 - val_loss: 10.5691 - val_mse: 10.5691\n",
      "Epoch 142/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.4057 - mse: 5.4057 - val_loss: 10.8307 - val_mse: 10.8307\n",
      "Epoch 143/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 5.5829 - mse: 5.5829 - val_loss: 10.4777 - val_mse: 10.4777\n",
      "Epoch 144/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 5.5353 - mse: 5.5353 - val_loss: 11.4378 - val_mse: 11.4378\n",
      "Epoch 145/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.2726 - mse: 5.2726 - val_loss: 10.2473 - val_mse: 10.2473\n",
      "Epoch 146/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.3735 - mse: 5.3735 - val_loss: 10.4933 - val_mse: 10.4933\n",
      "Epoch 147/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.4796 - mse: 5.4796 - val_loss: 11.7512 - val_mse: 11.7512\n",
      "Epoch 148/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.4649 - mse: 5.4649 - val_loss: 10.4111 - val_mse: 10.4111\n",
      "Epoch 149/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 5.3791 - mse: 5.3791 - val_loss: 10.8096 - val_mse: 10.8096\n",
      "Epoch 150/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.2176 - mse: 5.2176 - val_loss: 10.6270 - val_mse: 10.6270\n",
      "Epoch 151/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.2361 - mse: 5.2361 - val_loss: 10.6928 - val_mse: 10.6928\n",
      "Epoch 152/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 5.2775 - mse: 5.2775 - val_loss: 11.5336 - val_mse: 11.5336\n",
      "Epoch 153/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.4592 - mse: 5.4592 - val_loss: 10.5899 - val_mse: 10.5899\n",
      "Epoch 154/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.2576 - mse: 5.2576 - val_loss: 10.8510 - val_mse: 10.8510\n",
      "Epoch 155/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.2282 - mse: 5.2282 - val_loss: 10.6049 - val_mse: 10.6049\n",
      "Epoch 156/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.1903 - mse: 5.1903 - val_loss: 10.3287 - val_mse: 10.3287\n",
      "Epoch 157/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 5.2689 - mse: 5.2689 - val_loss: 10.8233 - val_mse: 10.8233\n",
      "Epoch 158/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.2262 - mse: 5.2262 - val_loss: 10.7024 - val_mse: 10.7024\n",
      "Epoch 159/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.2247 - mse: 5.2247 - val_loss: 10.3590 - val_mse: 10.3590\n",
      "Epoch 160/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.2512 - mse: 5.2512 - val_loss: 10.9652 - val_mse: 10.9652\n",
      "Epoch 161/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.1778 - mse: 5.1778 - val_loss: 10.5763 - val_mse: 10.5763\n",
      "Epoch 162/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.1584 - mse: 5.1584 - val_loss: 10.4792 - val_mse: 10.4792\n",
      "Epoch 163/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 5.1535 - mse: 5.1535 - val_loss: 10.4664 - val_mse: 10.4664\n",
      "Epoch 164/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.1613 - mse: 5.1613 - val_loss: 10.8212 - val_mse: 10.8212\n",
      "Epoch 165/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.1627 - mse: 5.1627 - val_loss: 10.6604 - val_mse: 10.6604\n",
      "Epoch 166/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.1355 - mse: 5.1355 - val_loss: 10.7066 - val_mse: 10.7066\n",
      "Epoch 167/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.1077 - mse: 5.1077 - val_loss: 10.4777 - val_mse: 10.4777\n",
      "Epoch 168/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.1514 - mse: 5.1514 - val_loss: 10.3411 - val_mse: 10.3411\n",
      "Epoch 169/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 5.2542 - mse: 5.2542 - val_loss: 10.1123 - val_mse: 10.1123\n",
      "Epoch 170/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.2716 - mse: 5.2716 - val_loss: 10.9610 - val_mse: 10.9610\n",
      "Epoch 171/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 5.2532 - mse: 5.2532 - val_loss: 10.4784 - val_mse: 10.4784\n",
      "Epoch 172/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.0822 - mse: 5.0822 - val_loss: 10.4263 - val_mse: 10.4263\n",
      "Epoch 173/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.0968 - mse: 5.0968 - val_loss: 10.6984 - val_mse: 10.6984\n",
      "Epoch 174/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.1073 - mse: 5.1073 - val_loss: 10.8062 - val_mse: 10.8062\n",
      "Epoch 175/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.0824 - mse: 5.0824 - val_loss: 10.5501 - val_mse: 10.5501\n",
      "Epoch 176/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.0514 - mse: 5.0514 - val_loss: 10.7560 - val_mse: 10.7560\n",
      "Epoch 177/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.1108 - mse: 5.1108 - val_loss: 10.4644 - val_mse: 10.4644\n",
      "Epoch 178/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 5.0756 - mse: 5.0756 - val_loss: 10.6523 - val_mse: 10.6523\n",
      "Epoch 179/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 5.0671 - mse: 5.0671 - val_loss: 10.4953 - val_mse: 10.4953\n",
      "Epoch 180/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.0384 - mse: 5.0384 - val_loss: 10.4048 - val_mse: 10.4048\n",
      "Epoch 181/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.0478 - mse: 5.0478 - val_loss: 10.6153 - val_mse: 10.6153\n",
      "Epoch 182/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.0039 - mse: 5.0039 - val_loss: 10.5355 - val_mse: 10.5355\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 183/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 4.9938 - mse: 4.9938 - val_loss: 10.6551 - val_mse: 10.6551\n",
      "Epoch 184/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 5.0430 - mse: 5.0430 - val_loss: 10.6240 - val_mse: 10.6240\n",
      "Epoch 185/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 4.9810 - mse: 4.9810 - val_loss: 10.2693 - val_mse: 10.2693\n",
      "Epoch 186/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.0167 - mse: 5.0167 - val_loss: 10.2235 - val_mse: 10.2235\n",
      "Epoch 187/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.0208 - mse: 5.0208 - val_loss: 10.2359 - val_mse: 10.2359\n",
      "Epoch 188/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 4.9695 - mse: 4.9695 - val_loss: 10.4737 - val_mse: 10.4737\n",
      "Epoch 189/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.0600 - mse: 5.0600 - val_loss: 10.3319 - val_mse: 10.3319\n",
      "Epoch 190/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.0296 - mse: 5.0296 - val_loss: 10.5578 - val_mse: 10.5578\n",
      "Epoch 191/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 4.9880 - mse: 4.9880 - val_loss: 10.1475 - val_mse: 10.1475\n",
      "Epoch 192/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 4.9663 - mse: 4.9663 - val_loss: 9.8895 - val_mse: 9.8895\n",
      "Epoch 193/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 4.9775 - mse: 4.9775 - val_loss: 10.2955 - val_mse: 10.2955\n",
      "Epoch 194/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.0742 - mse: 5.0742 - val_loss: 10.3740 - val_mse: 10.3740\n",
      "Epoch 195/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 4.9583 - mse: 4.9583 - val_loss: 10.0733 - val_mse: 10.0733\n",
      "Epoch 196/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.0439 - mse: 5.0439 - val_loss: 9.8801 - val_mse: 9.8801\n",
      "Epoch 197/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 5.2008 - mse: 5.2008 - val_loss: 10.5929 - val_mse: 10.5929\n",
      "Epoch 198/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 4.9864 - mse: 4.9864 - val_loss: 9.9884 - val_mse: 9.9884\n",
      "Epoch 199/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.2417 - mse: 5.2417 - val_loss: 9.8841 - val_mse: 9.8841\n",
      "Epoch 200/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.0338 - mse: 5.0338 - val_loss: 10.7287 - val_mse: 10.7287\n",
      "Epoch 201/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 4.8834 - mse: 4.8834 - val_loss: 9.9638 - val_mse: 9.9638\n",
      "Epoch 202/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.0351 - mse: 5.0351 - val_loss: 9.9605 - val_mse: 9.9605\n",
      "Epoch 203/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 5.0266 - mse: 5.0266 - val_loss: 10.2369 - val_mse: 10.2369\n",
      "Epoch 204/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 4.9853 - mse: 4.9853 - val_loss: 10.6894 - val_mse: 10.6894\n",
      "Epoch 205/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 4.8921 - mse: 4.8921 - val_loss: 9.8623 - val_mse: 9.8623\n",
      "Epoch 206/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.0987 - mse: 5.0987 - val_loss: 10.0818 - val_mse: 10.0818\n",
      "Epoch 207/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.0781 - mse: 5.0781 - val_loss: 10.4281 - val_mse: 10.4281\n",
      "Epoch 208/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 4.9242 - mse: 4.9242 - val_loss: 9.8852 - val_mse: 9.8852\n",
      "Epoch 209/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 4.8910 - mse: 4.8910 - val_loss: 10.2158 - val_mse: 10.2158\n",
      "Epoch 210/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 4.8410 - mse: 4.8410 - val_loss: 10.2652 - val_mse: 10.2652\n",
      "Epoch 211/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 4.8283 - mse: 4.8283 - val_loss: 9.8870 - val_mse: 9.8870\n",
      "Epoch 212/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 4.8462 - mse: 4.8462 - val_loss: 10.0924 - val_mse: 10.0924\n",
      "Epoch 213/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 4.9440 - mse: 4.9440 - val_loss: 9.7411 - val_mse: 9.7411\n",
      "Epoch 214/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 4.9094 - mse: 4.9094 - val_loss: 11.0622 - val_mse: 11.0622\n",
      "Epoch 215/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 4.9336 - mse: 4.9336 - val_loss: 10.0928 - val_mse: 10.0928\n",
      "Epoch 216/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 4.7768 - mse: 4.7768 - val_loss: 10.4223 - val_mse: 10.4223\n",
      "Epoch 217/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 4.9188 - mse: 4.9188 - val_loss: 10.3795 - val_mse: 10.3795\n",
      "Epoch 218/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 4.7384 - mse: 4.7384 - val_loss: 9.8626 - val_mse: 9.8626\n",
      "Epoch 219/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 4.8445 - mse: 4.8445 - val_loss: 9.9828 - val_mse: 9.9828\n",
      "Epoch 220/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 4.7866 - mse: 4.7866 - val_loss: 10.4268 - val_mse: 10.4268\n",
      "Epoch 221/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 4.8019 - mse: 4.8019 - val_loss: 10.0548 - val_mse: 10.0548\n",
      "Epoch 222/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 4.8028 - mse: 4.8028 - val_loss: 10.6523 - val_mse: 10.6523\n",
      "Epoch 223/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 4.8799 - mse: 4.8799 - val_loss: 9.9590 - val_mse: 9.9590\n",
      "Epoch 224/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 4.7739 - mse: 4.7739 - val_loss: 10.1242 - val_mse: 10.1242\n",
      "Epoch 225/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 4.7904 - mse: 4.7904 - val_loss: 9.9340 - val_mse: 9.9340\n",
      "Epoch 226/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 4.7393 - mse: 4.7393 - val_loss: 10.1565 - val_mse: 10.1565\n",
      "Epoch 227/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 4.7974 - mse: 4.7974 - val_loss: 10.1456 - val_mse: 10.1456\n",
      "Epoch 228/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 4.7430 - mse: 4.7430 - val_loss: 10.1417 - val_mse: 10.1417\n",
      "Epoch 229/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 4.8465 - mse: 4.8465 - val_loss: 10.2025 - val_mse: 10.2025\n",
      "Epoch 230/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 4.7544 - mse: 4.7544 - val_loss: 10.1147 - val_mse: 10.1147\n",
      "Epoch 231/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 4.8742 - mse: 4.8742 - val_loss: 9.9721 - val_mse: 9.9721\n",
      "Epoch 232/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 4.7338 - mse: 4.7338 - val_loss: 9.8049 - val_mse: 9.8049\n",
      "Epoch 233/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 4.7908 - mse: 4.7908 - val_loss: 10.0013 - val_mse: 10.0013\n",
      "Epoch 234/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 4.6884 - mse: 4.6884 - val_loss: 10.0697 - val_mse: 10.0697\n",
      "Epoch 235/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 4.6862 - mse: 4.6862 - val_loss: 9.9247 - val_mse: 9.9247\n",
      "Epoch 236/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 4.6728 - mse: 4.6728 - val_loss: 9.9723 - val_mse: 9.9723\n",
      "Epoch 237/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 4.6968 - mse: 4.6968 - val_loss: 9.9813 - val_mse: 9.9813\n",
      "Epoch 238/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 4.7603 - mse: 4.7603 - val_loss: 9.7330 - val_mse: 9.7330\n",
      "Epoch 239/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 4.7472 - mse: 4.7472 - val_loss: 10.0548 - val_mse: 10.0548\n",
      "Epoch 240/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 4.7207 - mse: 4.7207 - val_loss: 9.8186 - val_mse: 9.8186\n",
      "Epoch 241/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 4.6966 - mse: 4.6966 - val_loss: 9.9521 - val_mse: 9.9521\n",
      "Epoch 242/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 4.6377 - mse: 4.6377 - val_loss: 9.8210 - val_mse: 9.8210\n",
      "Epoch 243/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 4.6974 - mse: 4.6974 - val_loss: 9.8448 - val_mse: 9.8448\n",
      "Epoch 244/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 1ms/step - loss: 4.7310 - mse: 4.7310 - val_loss: 9.6179 - val_mse: 9.6179\n",
      "Epoch 245/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 4.7112 - mse: 4.7112 - val_loss: 9.8091 - val_mse: 9.8091\n",
      "Epoch 246/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 4.6945 - mse: 4.6945 - val_loss: 9.9480 - val_mse: 9.9480\n",
      "Epoch 247/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 4.6662 - mse: 4.6662 - val_loss: 9.5386 - val_mse: 9.5386\n",
      "Epoch 248/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 4.6108 - mse: 4.6108 - val_loss: 9.9027 - val_mse: 9.9027\n",
      "Epoch 249/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 4.6142 - mse: 4.6142 - val_loss: 9.7917 - val_mse: 9.7917\n",
      "Epoch 250/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 4.5784 - mse: 4.5784 - val_loss: 9.9246 - val_mse: 9.9246\n",
      "Epoch 251/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 4.5936 - mse: 4.5936 - val_loss: 9.7527 - val_mse: 9.7527\n",
      "Epoch 252/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 4.8043 - mse: 4.8043 - val_loss: 9.4603 - val_mse: 9.4603\n",
      "Epoch 253/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 4.8094 - mse: 4.8094 - val_loss: 10.7304 - val_mse: 10.7304\n",
      "Epoch 254/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 4.5892 - mse: 4.5892 - val_loss: 9.5485 - val_mse: 9.5485\n",
      "Epoch 255/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 4.5479 - mse: 4.5479 - val_loss: 9.7919 - val_mse: 9.7919\n",
      "Epoch 256/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 4.5608 - mse: 4.5608 - val_loss: 9.7907 - val_mse: 9.7907\n",
      "Epoch 257/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 4.6734 - mse: 4.6734 - val_loss: 10.0752 - val_mse: 10.0752\n",
      "Epoch 258/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 4.6197 - mse: 4.6197 - val_loss: 9.8554 - val_mse: 9.8554\n",
      "Epoch 259/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 4.5358 - mse: 4.5358 - val_loss: 9.6342 - val_mse: 9.6342\n",
      "Epoch 260/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 4.6911 - mse: 4.6911 - val_loss: 10.0404 - val_mse: 10.0404\n",
      "Epoch 261/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 4.8924 - mse: 4.8924 - val_loss: 9.7198 - val_mse: 9.7198\n",
      "Epoch 262/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 4.6785 - mse: 4.6785 - val_loss: 10.1525 - val_mse: 10.1525\n",
      "Epoch 263/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 4.5619 - mse: 4.5619 - val_loss: 9.5526 - val_mse: 9.5526\n",
      "Epoch 264/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 4.6020 - mse: 4.6020 - val_loss: 9.8295 - val_mse: 9.8295\n",
      "Epoch 265/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 4.5805 - mse: 4.5805 - val_loss: 9.5153 - val_mse: 9.5153\n",
      "Epoch 266/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 4.4961 - mse: 4.4961 - val_loss: 9.7092 - val_mse: 9.7092\n",
      "Epoch 267/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 4.4954 - mse: 4.4954 - val_loss: 9.4889 - val_mse: 9.4889\n",
      "Epoch 268/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 4.6180 - mse: 4.6180 - val_loss: 9.8341 - val_mse: 9.8341\n",
      "Epoch 269/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 4.6250 - mse: 4.6250 - val_loss: 9.2722 - val_mse: 9.2722\n",
      "Epoch 270/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 4.5276 - mse: 4.5276 - val_loss: 9.9580 - val_mse: 9.9580\n",
      "Epoch 271/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 4.5571 - mse: 4.5571 - val_loss: 9.5697 - val_mse: 9.5697\n",
      "Epoch 272/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 4.4520 - mse: 4.4520 - val_loss: 9.7343 - val_mse: 9.7343\n",
      "Epoch 273/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 4.4987 - mse: 4.4987 - val_loss: 9.6020 - val_mse: 9.6020\n",
      "Epoch 274/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 4.4448 - mse: 4.4448 - val_loss: 9.6112 - val_mse: 9.6112\n",
      "Epoch 275/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 4.5730 - mse: 4.5730 - val_loss: 9.5775 - val_mse: 9.5775\n",
      "Epoch 276/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 4.4146 - mse: 4.4146 - val_loss: 9.5021 - val_mse: 9.5021\n",
      "Epoch 277/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 4.4225 - mse: 4.4225 - val_loss: 9.5602 - val_mse: 9.5602\n",
      "Epoch 278/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 4.4635 - mse: 4.4635 - val_loss: 9.3605 - val_mse: 9.3605\n",
      "Epoch 279/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 4.4667 - mse: 4.4667 - val_loss: 9.4837 - val_mse: 9.4837\n",
      "Epoch 280/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 4.4126 - mse: 4.4126 - val_loss: 9.3642 - val_mse: 9.3642\n",
      "Epoch 281/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 4.3755 - mse: 4.3755 - val_loss: 9.8242 - val_mse: 9.8242\n",
      "Epoch 282/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 4.5171 - mse: 4.5171 - val_loss: 9.5892 - val_mse: 9.5892\n",
      "Epoch 283/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 4.5778 - mse: 4.5778 - val_loss: 9.6214 - val_mse: 9.6214\n",
      "Epoch 284/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 4.5000 - mse: 4.5000 - val_loss: 9.3760 - val_mse: 9.3760\n",
      "Epoch 285/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 4.4795 - mse: 4.4795 - val_loss: 9.0190 - val_mse: 9.0190\n",
      "Epoch 286/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 4.5728 - mse: 4.5728 - val_loss: 9.7725 - val_mse: 9.7725\n",
      "Epoch 287/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 4.4888 - mse: 4.4888 - val_loss: 9.6846 - val_mse: 9.6846\n",
      "Epoch 288/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 4.4773 - mse: 4.4773 - val_loss: 9.3004 - val_mse: 9.3004\n",
      "Epoch 289/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 4.4469 - mse: 4.4469 - val_loss: 9.8157 - val_mse: 9.8157\n",
      "Epoch 290/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 4.3795 - mse: 4.3795 - val_loss: 9.2044 - val_mse: 9.2044\n",
      "Epoch 291/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 4.3572 - mse: 4.3572 - val_loss: 9.5908 - val_mse: 9.5908\n",
      "Epoch 292/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 4.3064 - mse: 4.3064 - val_loss: 9.5082 - val_mse: 9.5082\n",
      "Epoch 293/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 4.3645 - mse: 4.3645 - val_loss: 9.6191 - val_mse: 9.6191\n",
      "Epoch 294/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 4.3006 - mse: 4.3006 - val_loss: 9.4916 - val_mse: 9.4916\n",
      "Epoch 295/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 4.2752 - mse: 4.2752 - val_loss: 9.3515 - val_mse: 9.3515\n",
      "Epoch 296/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 4.3046 - mse: 4.3046 - val_loss: 9.5049 - val_mse: 9.5049\n",
      "Epoch 297/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 4.2825 - mse: 4.2825 - val_loss: 9.3387 - val_mse: 9.3387\n",
      "Epoch 298/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 4.3249 - mse: 4.3249 - val_loss: 9.5410 - val_mse: 9.5410\n",
      "Epoch 299/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 4.2825 - mse: 4.2825 - val_loss: 9.5042 - val_mse: 9.5042\n",
      "Epoch 300/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 4.2841 - mse: 4.2841 - val_loss: 9.5421 - val_mse: 9.5421\n",
      "Epoch 301/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 4.3353 - mse: 4.3353 - val_loss: 9.3885 - val_mse: 9.3885\n",
      "Epoch 302/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 4.3266 - mse: 4.3266 - val_loss: 9.0731 - val_mse: 9.0731\n",
      "Epoch 303/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 4.2283 - mse: 4.2283 - val_loss: 9.2922 - val_mse: 9.2922\n",
      "Epoch 304/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 4.2822 - mse: 4.2822 - val_loss: 9.1108 - val_mse: 9.1108\n",
      "Epoch 305/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 4.2495 - mse: 4.2495 - val_loss: 9.6465 - val_mse: 9.6465\n",
      "Epoch 306/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 4.2443 - mse: 4.2443 - val_loss: 9.2627 - val_mse: 9.2627\n",
      "Epoch 307/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 4.3373 - mse: 4.3373 - val_loss: 9.5258 - val_mse: 9.5258\n",
      "Epoch 308/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 4.2797 - mse: 4.2797 - val_loss: 9.3643 - val_mse: 9.3643\n",
      "Epoch 309/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 4.5285 - mse: 4.5285 - val_loss: 8.7916 - val_mse: 8.7916\n",
      "Epoch 310/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 4.3005 - mse: 4.3005 - val_loss: 9.7378 - val_mse: 9.7378\n",
      "Epoch 311/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 4.2205 - mse: 4.2205 - val_loss: 9.1735 - val_mse: 9.1735\n",
      "Epoch 312/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 4.3157 - mse: 4.3157 - val_loss: 9.3553 - val_mse: 9.3553\n",
      "Epoch 313/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 4.2821 - mse: 4.2821 - val_loss: 9.6804 - val_mse: 9.6804\n",
      "Epoch 314/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 4.1904 - mse: 4.1904 - val_loss: 9.4518 - val_mse: 9.4518\n",
      "Epoch 315/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 4.1673 - mse: 4.1673 - val_loss: 9.3755 - val_mse: 9.3755\n",
      "Epoch 316/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 4.1377 - mse: 4.1377 - val_loss: 9.4206 - val_mse: 9.4206\n",
      "Epoch 317/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 4.1997 - mse: 4.1997 - val_loss: 9.2993 - val_mse: 9.2993\n",
      "Epoch 318/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 4.2467 - mse: 4.2467 - val_loss: 9.6340 - val_mse: 9.6340\n",
      "Epoch 319/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 4.2291 - mse: 4.2291 - val_loss: 9.0432 - val_mse: 9.0432\n",
      "Epoch 320/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 4.2448 - mse: 4.2448 - val_loss: 9.3997 - val_mse: 9.3997\n",
      "Epoch 321/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 4.2829 - mse: 4.2829 - val_loss: 9.2211 - val_mse: 9.2211\n",
      "Epoch 322/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 4.3618 - mse: 4.3618 - val_loss: 9.8408 - val_mse: 9.8408\n",
      "Epoch 323/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 4.1880 - mse: 4.1880 - val_loss: 8.9935 - val_mse: 8.9935\n",
      "Epoch 324/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 4.1298 - mse: 4.1298 - val_loss: 9.6434 - val_mse: 9.6434\n",
      "Epoch 325/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 4.1834 - mse: 4.1834 - val_loss: 8.9802 - val_mse: 8.9802\n",
      "Epoch 326/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 4.1856 - mse: 4.1856 - val_loss: 9.1917 - val_mse: 9.1917\n",
      "Epoch 327/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 4.1540 - mse: 4.1540 - val_loss: 9.4642 - val_mse: 9.4642\n",
      "Epoch 328/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 4.4041 - mse: 4.4041 - val_loss: 8.8090 - val_mse: 8.8090\n",
      "Epoch 329/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 4.2282 - mse: 4.2282 - val_loss: 9.7928 - val_mse: 9.7928\n",
      "Epoch 330/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 4.1617 - mse: 4.1617 - val_loss: 9.0109 - val_mse: 9.0109\n",
      "Epoch 331/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 4.1516 - mse: 4.1516 - val_loss: 9.3603 - val_mse: 9.3603\n",
      "Epoch 332/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 4.3599 - mse: 4.3599 - val_loss: 9.0790 - val_mse: 9.0790\n",
      "Epoch 333/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 4.3522 - mse: 4.3522 - val_loss: 9.6573 - val_mse: 9.6573\n",
      "Epoch 334/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 4.1127 - mse: 4.1127 - val_loss: 9.0307 - val_mse: 9.0307\n",
      "Epoch 335/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 4.1010 - mse: 4.1010 - val_loss: 9.3779 - val_mse: 9.3779\n",
      "Epoch 336/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 4.1292 - mse: 4.1292 - val_loss: 9.3467 - val_mse: 9.3467\n",
      "Epoch 337/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 4.0500 - mse: 4.0500 - val_loss: 9.2639 - val_mse: 9.2639\n",
      "Epoch 338/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 4.0396 - mse: 4.0396 - val_loss: 9.2075 - val_mse: 9.2075\n",
      "Epoch 339/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 4.0272 - mse: 4.0272 - val_loss: 9.3605 - val_mse: 9.3605\n",
      "Epoch 340/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 4.0065 - mse: 4.0065 - val_loss: 9.3299 - val_mse: 9.3299\n",
      "Epoch 341/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 4.0048 - mse: 4.0048 - val_loss: 9.4191 - val_mse: 9.4191\n",
      "Epoch 342/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 4.0173 - mse: 4.0173 - val_loss: 9.3892 - val_mse: 9.3892\n",
      "Epoch 343/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 4.1981 - mse: 4.1981 - val_loss: 9.2732 - val_mse: 9.2732\n",
      "Epoch 344/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 4.0840 - mse: 4.0840 - val_loss: 9.0146 - val_mse: 9.0146\n",
      "Epoch 345/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 4.0101 - mse: 4.0101 - val_loss: 9.2455 - val_mse: 9.2455\n",
      "Epoch 346/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 4.0142 - mse: 4.0142 - val_loss: 9.0693 - val_mse: 9.0693\n",
      "Epoch 347/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 3.9941 - mse: 3.9941 - val_loss: 9.7008 - val_mse: 9.7008\n",
      "Epoch 348/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 3.9879 - mse: 3.9879 - val_loss: 9.0731 - val_mse: 9.0731\n",
      "Epoch 349/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 4.0462 - mse: 4.0462 - val_loss: 9.0763 - val_mse: 9.0763\n",
      "Epoch 350/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 3.9636 - mse: 3.9636 - val_loss: 9.2220 - val_mse: 9.2220\n",
      "Epoch 351/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 3.9827 - mse: 3.9827 - val_loss: 9.0339 - val_mse: 9.0339\n",
      "Epoch 352/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 4.1975 - mse: 4.1975 - val_loss: 9.0764 - val_mse: 9.0764\n",
      "Epoch 353/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 4.0284 - mse: 4.0284 - val_loss: 9.4095 - val_mse: 9.4095\n",
      "Epoch 354/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 3.9329 - mse: 3.9329 - val_loss: 8.9270 - val_mse: 8.9270\n",
      "Epoch 355/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 3.9421 - mse: 3.9421 - val_loss: 9.1386 - val_mse: 9.1386\n",
      "Epoch 356/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 3.9282 - mse: 3.9282 - val_loss: 8.9121 - val_mse: 8.9121\n",
      "Epoch 357/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 3.9134 - mse: 3.9134 - val_loss: 8.9350 - val_mse: 8.9350\n",
      "Epoch 358/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 3.9218 - mse: 3.9218 - val_loss: 9.0164 - val_mse: 9.0164\n",
      "Epoch 359/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 4.0558 - mse: 4.0558 - val_loss: 9.0844 - val_mse: 9.0844\n",
      "Epoch 360/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 3.9264 - mse: 3.9264 - val_loss: 8.8577 - val_mse: 8.8577\n",
      "Epoch 361/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 3.9429 - mse: 3.9429 - val_loss: 8.9368 - val_mse: 8.9368\n",
      "Epoch 362/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 3.9519 - mse: 3.9519 - val_loss: 9.0233 - val_mse: 9.0233\n",
      "Epoch 363/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 4.0758 - mse: 4.0758 - val_loss: 8.7767 - val_mse: 8.7767\n",
      "Epoch 364/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 3.9711 - mse: 3.9711 - val_loss: 9.1713 - val_mse: 9.1713\n",
      "Epoch 365/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 4.0032 - mse: 4.0032 - val_loss: 8.8915 - val_mse: 8.8915\n",
      "Epoch 366/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 3.9394 - mse: 3.9394 - val_loss: 8.9703 - val_mse: 8.9703\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 367/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 3.8939 - mse: 3.8939 - val_loss: 9.0825 - val_mse: 9.0825\n",
      "Epoch 368/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 3.8897 - mse: 3.8897 - val_loss: 9.0048 - val_mse: 9.0048\n",
      "Epoch 369/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 4.0802 - mse: 4.0802 - val_loss: 9.1313 - val_mse: 9.1313\n",
      "Epoch 370/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 3.9422 - mse: 3.9422 - val_loss: 9.0083 - val_mse: 9.0083\n",
      "Epoch 371/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 3.8872 - mse: 3.8872 - val_loss: 8.9024 - val_mse: 8.9024\n",
      "Epoch 372/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 4.0123 - mse: 4.0123 - val_loss: 8.6092 - val_mse: 8.6092\n",
      "Epoch 373/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 4.0742 - mse: 4.0742 - val_loss: 8.9904 - val_mse: 8.9904\n",
      "Epoch 374/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 3.9212 - mse: 3.9212 - val_loss: 8.9131 - val_mse: 8.9131\n",
      "Epoch 375/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 3.9790 - mse: 3.9790 - val_loss: 9.1722 - val_mse: 9.1722\n",
      "Epoch 376/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 4.1109 - mse: 4.1109 - val_loss: 8.5712 - val_mse: 8.5712\n",
      "Epoch 377/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 3.7914 - mse: 3.7914 - val_loss: 9.2608 - val_mse: 9.2608\n",
      "Epoch 378/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 4.0265 - mse: 4.0265 - val_loss: 8.8158 - val_mse: 8.8158\n",
      "Epoch 379/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 4.2872 - mse: 4.2872 - val_loss: 9.4500 - val_mse: 9.4500\n",
      "Epoch 380/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 3.8883 - mse: 3.8883 - val_loss: 8.8035 - val_mse: 8.8035\n",
      "Epoch 381/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 3.6670 - mse: 3.6670 - val_loss: 9.4766 - val_mse: 9.4766\n",
      "Epoch 382/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 4.2263 - mse: 4.2263 - val_loss: 8.9725 - val_mse: 8.9725\n",
      "Epoch 383/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 3.8884 - mse: 3.8884 - val_loss: 8.7064 - val_mse: 8.7064\n",
      "Epoch 384/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 3.7514 - mse: 3.7514 - val_loss: 9.0309 - val_mse: 9.0309\n",
      "Epoch 385/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 3.8305 - mse: 3.8305 - val_loss: 8.8572 - val_mse: 8.8572\n",
      "Epoch 386/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 3.7688 - mse: 3.7688 - val_loss: 8.8687 - val_mse: 8.8687\n",
      "Epoch 387/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 3.7263 - mse: 3.7263 - val_loss: 9.0979 - val_mse: 9.0979\n",
      "Epoch 388/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 3.7607 - mse: 3.7607 - val_loss: 8.9615 - val_mse: 8.9615\n",
      "Epoch 389/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 3.8060 - mse: 3.8060 - val_loss: 9.0434 - val_mse: 9.0434\n",
      "Epoch 390/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 3.7796 - mse: 3.7796 - val_loss: 8.8187 - val_mse: 8.8187\n",
      "Epoch 391/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 3.8629 - mse: 3.8629 - val_loss: 8.7758 - val_mse: 8.7758\n",
      "Epoch 392/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 3.8398 - mse: 3.8398 - val_loss: 8.7255 - val_mse: 8.7255\n",
      "Epoch 393/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 3.8453 - mse: 3.8453 - val_loss: 9.0157 - val_mse: 9.0157\n",
      "Epoch 394/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 3.7753 - mse: 3.7753 - val_loss: 8.8536 - val_mse: 8.8536\n",
      "Epoch 395/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 3.8243 - mse: 3.8243 - val_loss: 8.6050 - val_mse: 8.6050\n",
      "Epoch 396/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 3.8447 - mse: 3.8447 - val_loss: 9.2176 - val_mse: 9.2176\n",
      "Epoch 397/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 3.7240 - mse: 3.7240 - val_loss: 8.7348 - val_mse: 8.7348\n",
      "Epoch 398/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 3.6989 - mse: 3.6989 - val_loss: 8.9195 - val_mse: 8.9195\n",
      "Epoch 399/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 3.6857 - mse: 3.6857 - val_loss: 8.9168 - val_mse: 8.9168\n",
      "Epoch 400/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 3.6505 - mse: 3.6505 - val_loss: 8.6467 - val_mse: 8.6467\n",
      "Epoch 401/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 3.7408 - mse: 3.7408 - val_loss: 9.0147 - val_mse: 9.0147\n",
      "Epoch 402/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 3.6484 - mse: 3.6484 - val_loss: 9.0025 - val_mse: 9.0025\n",
      "Epoch 403/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 3.6196 - mse: 3.6196 - val_loss: 8.7973 - val_mse: 8.7973\n",
      "Epoch 404/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 3.9484 - mse: 3.9484 - val_loss: 8.8911 - val_mse: 8.8911\n",
      "Epoch 405/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 3.8052 - mse: 3.8052 - val_loss: 9.2495 - val_mse: 9.2495\n",
      "Epoch 406/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 3.6339 - mse: 3.6339 - val_loss: 8.7055 - val_mse: 8.7055\n",
      "Epoch 407/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 3.7267 - mse: 3.7267 - val_loss: 8.9753 - val_mse: 8.9753\n",
      "Epoch 408/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 3.6647 - mse: 3.6647 - val_loss: 9.0692 - val_mse: 9.0692\n",
      "Epoch 409/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 3.6836 - mse: 3.6836 - val_loss: 8.9758 - val_mse: 8.9758\n",
      "Epoch 410/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 3.6751 - mse: 3.6751 - val_loss: 9.1209 - val_mse: 9.1209\n",
      "Epoch 411/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 4.1168 - mse: 4.1168 - val_loss: 9.1783 - val_mse: 9.1783\n",
      "Epoch 412/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 4.1116 - mse: 4.1116 - val_loss: 8.7004 - val_mse: 8.7004\n",
      "Epoch 413/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 4.2893 - mse: 4.2893 - val_loss: 9.6751 - val_mse: 9.6751\n",
      "Epoch 414/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 3.6043 - mse: 3.6043 - val_loss: 8.8521 - val_mse: 8.8521\n",
      "Epoch 415/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 3.7299 - mse: 3.7299 - val_loss: 8.6695 - val_mse: 8.6695\n",
      "Epoch 416/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 3.6614 - mse: 3.6614 - val_loss: 8.8749 - val_mse: 8.8749\n",
      "Epoch 417/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 3.5511 - mse: 3.5511 - val_loss: 8.8568 - val_mse: 8.8568\n",
      "Epoch 418/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 3.5823 - mse: 3.5823 - val_loss: 8.9155 - val_mse: 8.9155\n",
      "Epoch 419/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 3.5668 - mse: 3.5668 - val_loss: 8.9576 - val_mse: 8.9576\n",
      "Epoch 420/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 3.7165 - mse: 3.7165 - val_loss: 8.8897 - val_mse: 8.8897\n",
      "Epoch 421/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 3.6123 - mse: 3.6123 - val_loss: 9.1816 - val_mse: 9.1816\n",
      "Epoch 422/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 3.5859 - mse: 3.5859 - val_loss: 8.8154 - val_mse: 8.8154\n",
      "Epoch 423/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 3.5359 - mse: 3.5359 - val_loss: 8.8518 - val_mse: 8.8518\n",
      "Epoch 424/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 3.5783 - mse: 3.5783 - val_loss: 8.8631 - val_mse: 8.8631\n",
      "Epoch 425/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 3.5936 - mse: 3.5936 - val_loss: 8.7087 - val_mse: 8.7087\n",
      "Epoch 426/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 3.5962 - mse: 3.5962 - val_loss: 9.0843 - val_mse: 9.0843\n",
      "Epoch 427/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 3.5433 - mse: 3.5433 - val_loss: 8.5503 - val_mse: 8.5503\n",
      "Epoch 428/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 3.5820 - mse: 3.5820 - val_loss: 8.6741 - val_mse: 8.6741\n",
      "Epoch 429/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 3.5160 - mse: 3.5160 - val_loss: 8.9885 - val_mse: 8.9885\n",
      "Epoch 430/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 3.5627 - mse: 3.5627 - val_loss: 8.9242 - val_mse: 8.9242\n",
      "Epoch 431/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 3.5566 - mse: 3.5566 - val_loss: 8.7697 - val_mse: 8.7697\n",
      "Epoch 432/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 3.5093 - mse: 3.5093 - val_loss: 8.6907 - val_mse: 8.6907\n",
      "Epoch 433/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 3.4816 - mse: 3.4816 - val_loss: 8.5654 - val_mse: 8.5654\n",
      "Epoch 434/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 3.9521 - mse: 3.9521 - val_loss: 8.4482 - val_mse: 8.4482\n",
      "Epoch 435/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 3.8292 - mse: 3.8292 - val_loss: 9.6075 - val_mse: 9.6075\n",
      "Epoch 436/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 3.4731 - mse: 3.4731 - val_loss: 8.7386 - val_mse: 8.7386\n",
      "Epoch 437/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 3.6230 - mse: 3.6230 - val_loss: 9.1911 - val_mse: 9.1911\n",
      "Epoch 438/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 3.9028 - mse: 3.9028 - val_loss: 8.8996 - val_mse: 8.8996\n",
      "Epoch 439/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 3.4260 - mse: 3.4260 - val_loss: 8.7039 - val_mse: 8.7039\n",
      "Epoch 440/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 3.5431 - mse: 3.5431 - val_loss: 8.9109 - val_mse: 8.9109\n",
      "Epoch 441/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 3.4983 - mse: 3.4983 - val_loss: 8.8941 - val_mse: 8.8941\n",
      "Epoch 442/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 3.6699 - mse: 3.6699 - val_loss: 8.8721 - val_mse: 8.8721\n",
      "Epoch 443/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 3.4923 - mse: 3.4923 - val_loss: 8.5441 - val_mse: 8.5441\n",
      "Epoch 444/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 3.5658 - mse: 3.5658 - val_loss: 9.0187 - val_mse: 9.0187\n",
      "Epoch 445/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 3.4008 - mse: 3.4008 - val_loss: 8.4891 - val_mse: 8.4891\n",
      "Epoch 446/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 3.4704 - mse: 3.4704 - val_loss: 8.8045 - val_mse: 8.8045\n",
      "Epoch 447/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 3.4640 - mse: 3.4640 - val_loss: 8.7477 - val_mse: 8.7477\n",
      "Epoch 448/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 3.3961 - mse: 3.3961 - val_loss: 8.8303 - val_mse: 8.8303\n",
      "Epoch 449/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 3.4678 - mse: 3.4678 - val_loss: 9.1199 - val_mse: 9.1199\n",
      "Epoch 450/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 3.4470 - mse: 3.4470 - val_loss: 8.7274 - val_mse: 8.7274\n",
      "Epoch 451/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 3.4123 - mse: 3.4123 - val_loss: 9.0035 - val_mse: 9.0035\n",
      "Epoch 452/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 3.4504 - mse: 3.4504 - val_loss: 8.4764 - val_mse: 8.4764\n",
      "Epoch 453/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 3.3863 - mse: 3.3863 - val_loss: 8.7558 - val_mse: 8.7558\n",
      "Epoch 454/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 3.3786 - mse: 3.3786 - val_loss: 8.7000 - val_mse: 8.7000\n",
      "Epoch 455/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 3.4562 - mse: 3.4562 - val_loss: 8.9362 - val_mse: 8.9362\n",
      "Epoch 456/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 3.4137 - mse: 3.4137 - val_loss: 8.8468 - val_mse: 8.8468\n",
      "Epoch 457/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 3.3891 - mse: 3.3891 - val_loss: 8.7518 - val_mse: 8.7518\n",
      "Epoch 458/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 3.5180 - mse: 3.5180 - val_loss: 8.8521 - val_mse: 8.8521\n",
      "Epoch 459/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 3.3907 - mse: 3.3907 - val_loss: 8.7993 - val_mse: 8.7993\n",
      "Epoch 460/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 3.4280 - mse: 3.4280 - val_loss: 8.7415 - val_mse: 8.7415\n",
      "Epoch 461/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 3.5095 - mse: 3.5095 - val_loss: 8.7347 - val_mse: 8.7347\n",
      "Epoch 462/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 3.4853 - mse: 3.4853 - val_loss: 8.8323 - val_mse: 8.8323\n",
      "Epoch 463/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 3.4544 - mse: 3.4544 - val_loss: 8.6769 - val_mse: 8.6769\n",
      "Epoch 464/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 3.4208 - mse: 3.4208 - val_loss: 8.9784 - val_mse: 8.9784\n",
      "Epoch 465/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 3.3918 - mse: 3.3918 - val_loss: 8.5907 - val_mse: 8.5907\n",
      "Epoch 466/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 3.5531 - mse: 3.5531 - val_loss: 9.1652 - val_mse: 9.1652\n",
      "Epoch 467/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 3.3795 - mse: 3.3795 - val_loss: 8.9435 - val_mse: 8.9435\n",
      "Epoch 468/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 3.3957 - mse: 3.3957 - val_loss: 8.9794 - val_mse: 8.9794\n",
      "Epoch 469/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 3.3633 - mse: 3.3633 - val_loss: 8.8254 - val_mse: 8.8254\n",
      "Epoch 470/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 3.3522 - mse: 3.3522 - val_loss: 8.8069 - val_mse: 8.8069\n",
      "Epoch 471/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 3.4532 - mse: 3.4532 - val_loss: 8.7030 - val_mse: 8.7030\n",
      "Epoch 472/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 3.4138 - mse: 3.4138 - val_loss: 8.7739 - val_mse: 8.7739\n",
      "Epoch 473/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 3.3023 - mse: 3.3023 - val_loss: 8.8642 - val_mse: 8.8642\n",
      "Epoch 474/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 3.3115 - mse: 3.3115 - val_loss: 8.7726 - val_mse: 8.7726\n",
      "Epoch 475/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 3.2684 - mse: 3.2684 - val_loss: 8.9942 - val_mse: 8.9942\n",
      "Epoch 476/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 3.3272 - mse: 3.3272 - val_loss: 8.7794 - val_mse: 8.7794\n",
      "Epoch 477/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 3.2904 - mse: 3.2904 - val_loss: 8.5746 - val_mse: 8.5746\n",
      "Epoch 478/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 3.2418 - mse: 3.2418 - val_loss: 8.7578 - val_mse: 8.7578\n",
      "Epoch 479/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 3.2759 - mse: 3.2759 - val_loss: 8.6769 - val_mse: 8.6769\n",
      "Epoch 480/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 3.2568 - mse: 3.2568 - val_loss: 8.8359 - val_mse: 8.8359\n",
      "Epoch 481/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 3.3317 - mse: 3.3317 - val_loss: 9.0959 - val_mse: 9.0959\n",
      "Epoch 482/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 3.2810 - mse: 3.2810 - val_loss: 8.8391 - val_mse: 8.8391\n",
      "Epoch 483/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 3.3425 - mse: 3.3425 - val_loss: 8.8809 - val_mse: 8.8809\n",
      "Epoch 484/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 3.2384 - mse: 3.2384 - val_loss: 8.7065 - val_mse: 8.7065\n",
      "Epoch 485/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 3.2469 - mse: 3.2469 - val_loss: 8.7856 - val_mse: 8.7856\n",
      "Epoch 486/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 3.3920 - mse: 3.3920 - val_loss: 8.7431 - val_mse: 8.7431\n",
      "Epoch 487/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 3.3528 - mse: 3.3528 - val_loss: 8.7863 - val_mse: 8.7863\n",
      "Epoch 488/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 3.2389 - mse: 3.2389 - val_loss: 8.8028 - val_mse: 8.8028\n",
      "Epoch 489/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 3.2367 - mse: 3.2367 - val_loss: 8.6173 - val_mse: 8.6173\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 490/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 3.3058 - mse: 3.3058 - val_loss: 8.7684 - val_mse: 8.7684\n",
      "Epoch 491/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 3.2375 - mse: 3.2375 - val_loss: 8.7917 - val_mse: 8.7917\n",
      "Epoch 492/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 3.2473 - mse: 3.2473 - val_loss: 8.7425 - val_mse: 8.7425\n",
      "Epoch 493/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 3.2037 - mse: 3.2037 - val_loss: 8.5550 - val_mse: 8.5550\n",
      "Epoch 494/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 3.3756 - mse: 3.3756 - val_loss: 8.7269 - val_mse: 8.7269\n",
      "Epoch 495/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 3.3471 - mse: 3.3471 - val_loss: 8.9470 - val_mse: 8.9470\n",
      "Epoch 496/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 3.1867 - mse: 3.1867 - val_loss: 8.7149 - val_mse: 8.7149\n",
      "Epoch 497/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 3.2122 - mse: 3.2122 - val_loss: 8.9192 - val_mse: 8.9192\n",
      "Epoch 498/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 3.3323 - mse: 3.3323 - val_loss: 8.8998 - val_mse: 8.8998\n",
      "Epoch 499/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 3.3013 - mse: 3.3013 - val_loss: 8.7451 - val_mse: 8.7451\n",
      "Epoch 500/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 3.2241 - mse: 3.2241 - val_loss: 8.6704 - val_mse: 8.6704\n"
     ]
    }
   ],
   "source": [
    "model = build_model()\n",
    "history = model.fit(train_ds, epochs=500, validation_data=test_ds, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### history 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_history(history):\n",
    "\n",
    "    fig = plt.figure()\n",
    "    plt.plot(history.history['mse'], label='mean_squared_error')\n",
    "    plt.plot(history.history['val_mse'], label='val_mean_squared_error')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('Mean Squared Error [MPG]')\n",
    "    plt.legend()\n",
    "\n",
    "    fig = plt.figure()\n",
    "    plt.plot(history.history['loss'], label='loss')\n",
    "    plt.plot(history.history['val_loss'], label='val_loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('Loss[MPG]')\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEGCAYAAACKB4k+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAgAElEQVR4nO3de5gcdZ3v8fe3urqnJ/crCSRowiEalSzIRoRVUGF1kaOAKCKCIAflHGVBxIcVUY+XxV13PSure3xQ1ltwUYlcVhZYWRZQ5DmKhBgINyGyXCaEZBJyn8x0d9X3/FG/7nQmkzCTTE1n0p/X8/RTVb+69Pc3093f+v3qZu6OiIgIQNTqAEREZN+hpCAiIg1KCiIi0qCkICIiDUoKIiLSELc6gL0xbdo0nzNnTqvDEBEZVR588MG17j59oHmjOinMmTOHJUuWtDoMEZFRxcye3dU8dR+JiEiDkoKIiDQoKYiISMOoPqYgIu2pWq3S1dVFb29vq0PZp5XLZWbPnk2xWBz0OkoKIjLqdHV1MX78eObMmYOZtTqcfZK7s27dOrq6upg7d+6g11P3kYiMOr29vUydOlUJYTfMjKlTpw65NaWkICKjkhLCy9uTv1GuScHMJpnZDWb2hJk9bmbHmNkUM7vTzJ4Kw8lhWTOzb5rZCjN72MyOzC2wZ38Dd/01JLXc3kJEZDTKu6XwDeAX7j4fOBx4HLgcuMvd5wF3hWmAdwLzwusC4Orcoup6AH79f6C2Lbe3EJH927hx41odQi5ySwpmNhE4DvgegLtX3H0DcAqwKCy2CDg1jJ8CXOuZ3wKTzOzAXIIrdmbDqs5cEBFplmdLYS7QDfzAzH5vZt81s7HADHdfFZZ5EZgRxmcBzzet3xXKdmBmF5jZEjNb0t3dvWeRxeVsqJaCiOwld+eyyy7jsMMOY8GCBVx//fUArFq1iuOOO44jjjiCww47jF//+tckScKHP/zhxrJXXXVVi6PfWZ6npMbAkcBF7n6/mX2D7V1FALi7m9mQngfq7tcA1wAsXLhwz54lqpaCyH7jS//2KI+9sGlYt/nagybwhXe/blDL3nTTTSxbtoyHHnqItWvX8oY3vIHjjjuOH//4x/zFX/wFn/3sZ0mShJ6eHpYtW8bKlSt55JFHANiwYcOwxj0c8mwpdAFd7n5/mL6BLEmsrncLheGaMH8lcHDT+rND2fBTS0FEhsl9993HmWeeSaFQYMaMGbzlLW/hgQce4A1veAM/+MEP+OIXv8jy5csZP348hxxyCE8//TQXXXQRv/jFL5gwYUKrw99Jbi0Fd3/RzJ43s1e7+x+AE4DHwutc4Kth+POwyi3AX5rZT4E3AhubupmGVzEkBbUUREa9we7Rj7TjjjuOe++9l9tuu40Pf/jDXHrppZxzzjk89NBD3HHHHXz7299m8eLFfP/73291qDvI++yji4DrzOxh4Ajgb8iSwdvN7Cngz8M0wO3A08AK4J+Bj+cWVRy6j9RSEJG9dOyxx3L99deTJAnd3d3ce++9HHXUUTz77LPMmDGDj370o3zkIx9h6dKlrF27ljRNee9738uVV17J0qVLWx3+TnK9zYW7LwMWDjDrhAGWdeDCPONpUEtBRIbJe97zHn7zm99w+OGHY2b8/d//PTNnzmTRokV87Wtfo1gsMm7cOK699lpWrlzJeeedR5qmAPzt3/5ti6PfmWW/xaPTwoULfY8esrP6Mbj6GDj9h/C69wx7XCKSr8cff5zXvOY1rQ5jVBjob2VmD7r7QDvsbXqbC7UUREQG1JZJ4YaH1gJQ7etpcSQiIvuWtkwK2+gAoKakICKyg7ZMCqXyGEAtBRGR/toyKXR0dJK6kSgpiIjsoC2TQmdHTB9FahVdpyAi0qw9k0KxQC8lvKKWgohIs7ZMCmNKWVJI1VIQkRGwu2cvPPPMMxx22GEjGM3utWVSKBcL9HoR13UKIiI7yPU2F/uqzlKBCkU6an2tDkVE9ta/Xw4vLh/ebc5cAO/86i5nX3755Rx88MFceGF2Z54vfvGLxHHMPffcw/r166lWq1x55ZWccsopQ3rb3t5ePvaxj7FkyRLiOObrX/86b3vb23j00Uc577zzqFQqpGnKjTfeyEEHHcT73/9+urq6SJKEz3/+85xxxhl7VW1o06QwplSgmyLjamopiMjQnXHGGVxyySWNpLB48WLuuOMOLr74YiZMmMDatWs5+uijOfnkkzGzQW/3W9/6FmbG8uXLeeKJJ3jHO97Bk08+ybe//W0+8YlPcNZZZ1GpVEiShNtvv52DDjqI2267DYCNGzcOS93aMil0FrOWgiWVVociIntrN3v0eXn961/PmjVreOGFF+ju7mby5MnMnDmTT37yk9x7771EUcTKlStZvXo1M2fOHPR277vvPi666CIA5s+fzytf+UqefPJJjjnmGL7yla/Q1dXFaaedxrx581iwYAGf+tSn+PSnP8273vUujj322GGpW1seU+gsFah4DOo+EpE9dPrpp3PDDTdw/fXXc8YZZ3DdddfR3d3Ngw8+yLJly5gxYwa9vcPTG/HBD36QW265hc7OTk466STuvvtuXvWqV7F06VIWLFjA5z73Ob785S8Py3u1ZUuhVIioUCRKlBREZM+cccYZfPSjH2Xt2rX86le/YvHixRxwwAEUi0Xuuecenn322SFv89hjj+W6667j+OOP58knn+S5557j1a9+NU8//TSHHHIIF198Mc899xwPP/ww8+fPZ8qUKZx99tlMmjSJ7373u8NSr7ZMCmZGLSph6ZZWhyIio9TrXvc6Nm/ezKxZszjwwAM566yzePe7382CBQtYuHAh8+fPH/I2P/7xj/Oxj32MBQsWEMcxP/zhD+no6GDx4sX86Ec/olgsMnPmTK644goeeOABLrvsMqIoolgscvXVVw9LvdrzeQrAf3zpJF5ffI7pVzwyzFGJSN70PIXB0/MUBimJShRSHWgWEWnWlt1HAGmhREFnH4nICFm+fDkf+tCHdijr6Ojg/vvvb1FEA2vbpOCFDuJqtdVhiMgecvchXQPQagsWLGDZsmUj+p57cnigbbuP0qhE0dVSEBmNyuUy69at26MfvXbh7qxbt45yuTyk9dq2pWBxBzFVcIdRtLchIjB79my6urro7u5udSj7tHK5zOzZs4e0TtsmBeIOIhzSGhSKrY5GRIagWCwyd+7cVoexX2rb7iPi7DnN6P5HIiINuSYFM3vGzJab2TIzWxLKppjZnWb2VBhODuVmZt80sxVm9rCZHZlrbI2koOMKIiJ1I9FSeJu7H9F0ocTlwF3uPg+4K0wDvBOYF14XAMNzed4uRMVw8EW3uhARaWhF99EpwKIwvgg4tan8Ws/8FphkZgfmFUQ9KaQVdR+JiNTlnRQc+A8ze9DMLghlM9x9VRh/EZgRxmcBzzet2xXKdmBmF5jZEjNbsjdnHhSKWfdRX5+e0ywiUpf32UdvdveVZnYAcKeZPdE8093dzIZ0orG7XwNcA9m9j/Y0sLijE8iedNS5pxsREdnP5NpScPeVYbgGuBk4Clhd7xYKwzVh8ZXAwU2rzw5luSiE7qNKr1oKIiJ1uSUFMxtrZuPr48A7gEeAW4Bzw2LnAj8P47cA54SzkI4GNjZ1Mw27uJQlhWrftrzeQkRk1Mmz+2gGcHO4N0kM/Njdf2FmDwCLzex84Fng/WH524GTgBVAD3BejrFR6siSQl+fzj4SEanLLSm4+9PA4QOUrwNOGKDcgQvziqe/Yik70FzR2UciIg1te0VzMXQfJVW1FERE6to2KcShpZBWdUWziEhd2yaFevdRUlNLQUSkrm2TQil0H6mlICKyXdsmhXpLIdUN8UREGto2KdRbCq7uIxGRhvZNCmW1FERE+mvfpFBvKSRKCiIidW2bFOK4SOoGtWqrQxER2We0bVLAjCqxWgoiIk3aNykAVYtBSUFEpKGtk0KNGFJ1H4mI1LV3UrAYS5QURETq2jspUAQlBRGRhrZOConFmLqPREQa2jwpFIlSHWgWEalr86SgloKISLP2TgpRkUhJQUSkoa2TQhoVKbiSgohInZKC11odhojIPqOtk4JHRQrqPhIRaWjvpGBFCqilICJS19ZJIY2KxDqmICLSkHtSMLOCmf3ezG4N03PN7H4zW2Fm15tZKZR3hOkVYf6cvGPzQpFYLQURkYaRaCl8Ani8afrvgKvc/VBgPXB+KD8fWB/KrwrL5cqjIrEONIuINOSaFMxsNvDfge+GaQOOB24IiywCTg3jp4RpwvwTwvL5UUtBRGQHebcU/hH4KyAN01OBDe6N3fMuYFYYnwU8DxDmbwzL5ycqEpOQpJ7r24iIjBa5JQUzexewxt0fHObtXmBmS8xsSXd3995tLIopklBN0pdfVkSkDeTZUngTcLKZPQP8lKzb6BvAJDOLwzKzgZVhfCVwMECYPxFY13+j7n6Nuy9094XTp0/fuwgLWUtBSUFEJJNbUnD3z7j7bHefA3wAuNvdzwLuAd4XFjsX+HkYvyVME+bf7e759uuEYwrVRN1HIiLQmusUPg1camYryI4ZfC+Ufw+YGsovBS7POxArFClZQrWW5P1WIiKjQvzyi+w9d/8l8Msw/jRw1ADL9AKnj0Q8dVYoAlCpVIDOkXxrEZF9Ultf0WxxCYBaVQ/aERGBdk8KoaWgpCAikmnrpBDVk0JNSUFEBAZxTMHMLh3Edra6+3eGIZ4RZXGWFKpqKYiIAINrKVwGjAPG7+b1qbwCzFOhkB1TSJUURESAwZ199CN3//LuFjCzscMUz4iKillLIVH3kYgIMIiWgrv/1XAssy+KQktBxxRERDKDOaYwG5jj7veF6UvJupMAfuzuK3KML1dROKaQVPpaHImIyL5hMMcUvgZMapr+n8BWwIEv5RHUSInDdQpJTU9fExGBwR1TeLW739o03ePu/wBgZr/OJ6yRERU7AEiVFEREgMG1FMr9pk9oGp82jLGMuEKsA80iIs0GkxQ2m9mr6hPu/hKAmc0HNucV2EiIi+GU1ERJQUQEBtd99AXgVjP7CrA0lP0pcAXZ85dHrUJcv05B3UciIjCIpODuvzCz08geq3lxKH4EOM3dH8kzuLzFpSwpeKKkICICg7919mrgm8AKd9+QYzwjqt59lKj7SEQEGMQxBTP7CPAo8E/AE2Z2cu5RjZD6KanoQLOICDC4lsIlwOvcvdvMDgGuI3t05qgXxeo+EhFpNpizjyru3g2Np6Z15BvSCIqynOhJrcWBiIjsGwbTUphtZt/c1bS7XzzAOqNDod5SUPeRiAgMLilc1m/6wTwCaYnwkB11H4mIZAZzSuqikQikJUL3EUoKIiLA4O6SutuDyu4+es9GCi0FS3VMQUQEBtd9dAzwPPAT4H7Aco1oJEXqPhIRaTaYpDATeDtwJvBB4DbgJ+7+aJ6BjYhGS0FJQUQEBvfktcTdf+Hu5wJHAyuAX5rZX+5uPTMrm9nvzOwhM3vUzL4Uyuea2f1mtsLMrjezUijvCNMrwvw5e127l2NGQqTuIxGRYDDXKdR/sE8D/gW4kOyWFze/zGp9wPHufjhwBHCimR0N/B1wlbsfCqwHzg/Lnw+sD+VXheVyVyNWS0FEJBjMbS6uBX4DHAl8yd3f4O5/7e4rd7eeZ7aEyWJ4OXA8cEMoXwScGsZPCdOE+SeYWe7HLxKLQS0FERFgcC2Fs4F5ZLfJ/n9mtim8NpvZpt2taGYFM1sGrAHuBP4IbHD3+q9wFzArjM8iO6BNmL8RmDrANi8wsyVmtqS7u3sQ4e9eYmopiIjUDeY6hUF1Me1i3QQ4wswmkXU3zd/TbTVt8xrgGoCFCxf63m4vsZhILQUREWCQxxT2Vrjd9j1kp7dOMrN6MpoN1LuhVgIHA4T5E4F1eceWWoy5koKICAzumMLSPVnGzKaHFgJm1kl2WuvjZMnhfWGxc4Gfh/FbwjRh/t3uvtctgZejloKIyHaDuU7hNWb28G7mG9lefX8HAovMrECWfBa7+61m9hjwUzO7Evg98L2w/PeAH5nZCuAl4AODrcTeSJUUREQaBpMUBnMcIOlf4O4PA68foPxp4KgBynuB0wfxXsMqtZiCDjSLiACDu3jtWXd/liyBvBjG55KdQroxzO/KOc7ceBQT6ZiCiAgwtAPNNwKJmR1KdvbPwcCPc4lqBKUWE6GkICICQ0sKabh+4DTgn9z9MrLjBqOaRzEFtRRERIChJYWqmZ0JnAPcGsqKwx/SyEqjIgXf6ZCIiEhbGkpSOI/sOoOvuPt/mdlc4Ef5hDWCoiIxNdI097NfRUT2eYM5+wgAd38MuBjAzCYD4919RG5alyePYmISqmlKR1RodTgiIi016JaCmf3SzCaY2RRgKfDPZvb1/EIbIVGRIgnVRC0FEZGhdB9NdPdNZAear3X3NwJ/nk9YI8cLMUVqVGtpq0MREWm5oSSF2MwOBN7P9gPNo19UJCahkigpiIgMJSl8GbgD+KO7P2BmhwBP5RPWCCoUiS2hqqQgIjKkA80/A37WNP008N48ghpJFrqPenRMQURkSAeaZ5vZzWa2JrxuNLPZeQY3IkL3UU0tBRGRIXUf/YDs9tYHhde/hbLRrVCiqGMKIiLA0JLCdHf/gbvXwuuHwPSc4hoxFmctBZ2SKiIytKSwzszODs9dLpjZ2YzAk9HyZoXsimZ1H4mIDC0p/A+y01FfBFaRPR3twznENKKsUKRkCZWa7n8kIjLopBCem3Cyu0939wPc/VT2g7OPokJ2T79aTQ/aEREZSkthIJcOSxQtFMUlAJJqpcWRiIi03t4mBRuWKFrIQkshqSkpiIjsbVIY9afsFOLQfVRV95GIyMte0Wxmmxn4x9+AzmGPaITVu49StRRERF4+Kbj7+JEIpFWiYjimoKQgIrLX3UejXiG0FHT2kYiIkkIjKXi1r8WRiIi0Xm5JwcwONrN7zOwxM3vUzD4RyqeY2Z1m9lQYTg7lZmbfNLMVZvawmR2ZV2zNonCgOU3UfSQikmdLoQZ8yt1fCxwNXGhmrwUuB+5y93nAXWEa4J3AvPC6ALg6x9ga4mL9QHNtJN5ORGSflltScPdV7r40jG8GHgdmAacAi8Jii4BTw/gpZI/5dHf/LTApPOktV4WCzj4SEakbkWMKZjYHeD1wPzDD3VeFWS8CM8L4LOD5ptW6Qln/bV1gZkvMbEl3d/dex6buIxGR7XJPCmY2DrgRuMTdNzXPc3dniBfAufs17r7Q3RdOnz4Md+4OVzR7ou4jEZFck4KZFckSwnXuflMoXl3vFgrDNaF8JXBw0+qzQ1m+opAU1H0kIpLr2UcGfA943N2/3jTrFuDcMH4u8POm8nPCWUhHAxubupny02gp6DoFEZGXvaJ5L7wJ+BCw3MyWhbIrgK8Ci83sfOBZsmc0ANwOnASsAHqA83KMbbuQFFBSEBHJLym4+33s+i6qJwywvAMX5hXPLkVqKYiI1LX9Fc3qPhIR2U5JIcoaS5YqKYiIKCmopSAi0qCkENUPNOs6BRERJYVCONau7iMRESUFnX0kIrKdkkK4IZ66j0RElBQaB5qjVLe5EBFRUjAjoaBjCiIiKCkAkFoBS9V9JCKipAAkFispiIigpABAajHmSgoiIkoKQBrFRGopiIgoKQC4xRS8RpIO6SFwIiL7HSUFII2KxJZQqaWtDkVEpKWUFACPipSoKSmISNtTUgA8iolJ6EuSVociItJSSgoAUZFYLQURESUFAI876KBKn5KCiLQ5JQUgLZQpW0UtBRFpe0oKAHGZTpQURESUFAAvjqFMRd1HItL2lBQAK6r7SEQElBQyxU46qFDRKaki0uZySwpm9n0zW2NmjzSVTTGzO83sqTCcHMrNzL5pZivM7GEzOzKvuAYSFbNjCtsqaimISHvLs6XwQ+DEfmWXA3e5+zzgrjAN8E5gXnhdAFydY1w7iTuyYwpbK7opnoi0t9ySgrvfC7zUr/gUYFEYXwSc2lR+rWd+C0wyswPziq2/YnkssaX0bNs2Um8pIrJPGuljCjPcfVUYfxGYEcZnAc83LdcVynZiZheY2RIzW9Ld3T0sQRXLYwDo27Z1WLYnIjJatexAs7s7MOR7Vbv7Ne6+0N0XTp8+fVhiiUshKfT2DMv2RERGq5FOCqvr3UJhuCaUrwQOblpudigbGcVOAGq9aimISHsb6aRwC3BuGD8X+HlT+TnhLKSjgY1N3Uz5i8sAVPvUUhCR9hbntWEz+wnwVmCamXUBXwC+Ciw2s/OBZ4H3h8VvB04CVgA9wHl5xTWgYtZ9VFNSEJE2l1tScPczdzHrhAGWdeDCvGJ5WcWspZBWdPaRiLQ3XdEMEGfHFBK1FESkzSkpQONAM1UlBRFpb0oKAGOmAlCurG9xICIiraWkADA2u95hbK3/BdgiIu1FSQGgWKavMI7xtfVsq+hOqSLSvpQUgr7ydKbZRlZv6m11KCIiLaOkEPjY6UxXUhCRNqekEETjD2AaG3lRSUFE2piSQlCacjCzbC3dGza3OhQRkZZRUghKc4+hbFXS55e0OhQRkZZRUghszrGkGGNX/abVoYiItIySQt2YKXSPOZRDtvyeSk3PahaR9qSk0GTrQX/GkfYkT3YNzxPdRERGGyWFJuNf8+d0WJXVj9zd6lBERFpCSaHJtAUn0EuR8n/9Z6tDERFpCSWFJlYay2OdC5n/0l1Qq7Q6HBGREaek0M/qV32Qqb6eDff/qNWhiIiMOCWFfua88WR+nx5K+Zd/Dd1PtjocEZERpaTQz/wDJ/KNcZ+kL0nhn98Gy34C7q0OS0RkRCgp9GNmHPPGYzix50o2T34t/Ov/ghs/Aj161oKI7P+UFAZw9tGvpDb+ID7Q91mqb/ksPHoz/MOr4ScfhOU3QGVrq0MUEclF3OoA9kVjO2K+etoCPnLtEj7wxJv5vx+4kwP/60Z49Cb4w21QHAPz3gHTXw3lidAxIRuWJ8K4A2DcDChPgkg5V0RGF/NR3F++cOFCX7IkvxvY/dtDL3DFTcvpq6WceNhMTpg/jeM6VjD56VvgD/8Om1ftemWLsuQRd0ChBFERCsVsvBDvWDZuBnROht6N4CmUxgIOSS0bj2IodmbbTKvZep5k2y+UoHcDVLdB5xSo9UKtL5vfOQXMsjIMxk6DNMnmjZkKpXGwLXSLlSdCx0TYuiaLuf652LIGOsZB3Jmtt3UtdE6CCbOy96lty+IaewBEhSyO1Y9m77VyKcxemG1r/TMwZW5W175NWb22dMP4GVnLK4qzeOMOWLcii6dvczYdxVk9SuMgqULSB6Xx2d8sirb/rStbsveq9WUxb14N46ZD76asLsXO7JVUoWN8VpfuJ2DSK7JknibZ/7Q4BsbPzP5mtW1ghew96q+oAHEZkkoWEw5pLVu/2JnFUIizOrtnf6vKlqxO1W3Zep2TszrV/85pLfssiIwAM3vQ3RcOOE9JYfde2LCN7/zqj/zrshfYuK0KwIwJHbxiyhheMamDAztrzCj1Ma3Yx3jfwoTaS4yrrqOztoGSVyh6hQI1CmmVAjWitEqU1rC0mv04JFXY2JX9aHSMByxLDjv80KVQ7cmGUTFLDFbIhpCtE8XbE0Zczn5w+jbl+reRAViU/Z+KY6Hav5vRAN8+XhyTjabVkKgmZPPricei7P8cFUJiIvusFErhVQzLhp2MemIqT8g+Bz3rsnWjONsxKI3LYkuq2br1RNW3Gaq92eevY3xWXu2BMdOy8bic7RBEcdMrbDetweYXYfKcUD+yz16jvmE6KmQ7OcVylgg9yYb1RFvrzbZV3ZYNLYIJB2WxergXWbEz20mobM12Uno3ZvFGhWy8HlNzjJ7CCw/BAa/J1k2q22NKkyzpu8OkV4b/QyX7361/Bratz3Yuxs3Iyj3N6mSWDfs2ZzGNnR5i78m2Xf9/1ePoWZvtmNT/LwNJ+rK6l8Zt/7/W36c+rPZk/+f6zsiRH4JD3roHH9JRlBTM7ETgG0AB+K67f3V3y49EUqhLUufxVZv4zR/X8YfVm3nupR5Wrt/GS1srbKsO/bnOkUFciIgjy15N44WCEVn2Msu+WgUcswiLDDMjMihTITKnZqXG9opxETMoREaJGmYRcZRSsoQiNcwKpFZgbLKRzmQLWwqTMIOxvpWxyWZ64wlE4T1KVNhQmkmcbCOu9WKk9JSmMj7dzITaOmqFDpJCmchTxtdewoBq6my28Uy3jbzUMYu4tpUoLlErTaRc3ciY2noqhTGUkh62lqYyprqRWqEMwJjaRsq1TWwpTcejmGo8hjitUvAqTkQp7SGNiiRWoiPdSrm6EXAMp6O2lWqc/cjGaR+Rp6RRjHlKpTiBjtoWaoUOSslWkkKZYq2HyBMqxfEk5clMqKwhKXTS0zGdct9aCsk2ANJCGcMxUszTMHTiWg8eFSgkfWARHmU9saXKRpK4TLG6mSjpw6Mi1dIkaqXxlPrWZ9vzlELSQ5RUACdK+kjiMdn2jWzoSfa+nmCeEnmNuLKJbRMPzfYB0iqFtIqREnlClFbwqARmFHo3YF4jLY7Jfpxq26B3M1F5PMRlPPywOBFRZRNp3EkhrRB59mOcVraBGRZ3kFCg4DXonIilKeY1SGtYmmRDErw0nqiyqZ4CMo3flWxoSV82mabZtkPSS9Ok0XqNPKVaKFOIItK4k7inm6hjzPaWWqUHqj14aSzWuwkvjSUi3d7ycsdDYjSvQZJQq1aodUygnG7DzLIfVTwLK4qy5JJWYdMqiLPWu1d7su2MmQbliVjPOizuyGLAQ90cCh3ZD/nW7iw5lMaG1nySbbNet2I5a3n2bsqmB/xBKGTrV7aEC2eb3qc+rMdaKGXLvfUK+JPTh/zbA6MkKZhZAXgSeDvQBTwAnOnuj+1qnZFMCruzrZKwvqdCTyWht5rQU0noqdQa45VaSiVJqdRS+mrZMEmdWurUkjQbpim1ZHuZk30WUvedhqkDZMP6tLvTF7abpB7KnSSFNEwn7qSpZ1+OJvVl05Qd1nP37LsTklB92WqSLVP/bjXH1hFHFCJjS1+NQpQltkotJen3OdtHPnayH2juhdvdMgbEUbR9+VBW3/mKzBptuS19tca6ncUCTva5H1Mq0BEXGt8NsvUjaJ4AAAdoSURBVM2ExpHR76u1k8jAyL5P1vy+1mhX7fT9bNSh3/Qlb38VJx9+0O7fcBd2lxT2pQPNRwEr3P1pADP7KXAKsMuksK/oLBXoLHW2OoxRqb5TEnJMo6yeFAEc3+FLny2743qN7TSth++47kDL1b/sfaG1FzV9IXe53Z22uXOc/WPcVez1H4RG4u9X/4HG6wk58aYdgKa7vff/fYwMysUCm7ZVsx0InIJtb3ECjUTvQDmOiMzorSV0xAX6agl91Z1vJ+/02+EY6Ie5/85AU10Sh1IcUSoYqWc7V5PGFNkUumkTh96mVrjt8IOabae+wxVZ1sqOIsu2HXZwZk3uxIBn1m3FsJ12jBp/03T739YdZk4sN3bYNm6rUgwt+Z5KQiVJG4nAMJz6jlm9hrvKDP138LZ/ZtKm78HAa+5s8ph8jkHtS0lhFvB803QX8Mb+C5nZBcAFAK94xStGJjLJTf3LuePO0cvsbolIbkbdOZPufo27L3T3hdOnT291OCIi+5V9KSmsBA5ump4dykREZITsS0nhAWCemc01sxLwAeCWFsckItJW9pljCu5eM7O/BO4gOyX1++7+aIvDEhFpK/tMUgBw99uB21sdh4hIu9qXuo9ERKTFlBRERKRBSUFERBr2mdtc7Akz6wae3cPVpwFrhzGc0UB1bg+qc3vYmzq/0t0HvNBrVCeFvWFmS3Z174/9lercHlTn9pBXndV9JCIiDUoKIiLS0M5J4ZpWB9ACqnN7UJ3bQy51bttjCiIisrN2bimIiEg/SgoiItLQlknBzE40sz+Y2Qozu7zV8QwXM/u+ma0xs0eayqaY2Z1m9lQYTg7lZmbfDH+Dh83syNZFvufM7GAzu8fMHjOzR83sE6F8v623mZXN7Hdm9lCo85dC+Vwzuz/U7fpwt2HMrCNMrwjz57Qy/j1lZgUz+72Z3Rqm9+v6ApjZM2a23MyWmdmSUJbrZ7vtkkJ4FvS3gHcCrwXONLPXtjaqYfND4MR+ZZcDd7n7POCuMA1Z/eeF1wXA1SMU43CrAZ9y99cCRwMXhv/n/lzvPuB4dz8cOAI40cyOBv4OuMrdDwXWA+eH5c8H1ofyq8Jyo9EngMebpvf3+ta9zd2PaLomId/Ptru31Qs4BrijafozwGdaHdcw1m8O8EjT9B+AA8P4gcAfwvh3gDMHWm40v4CfA29vl3oDY4ClZI+uXQvEobzxOSe7Hf0xYTwOy1mrYx9iPWeHH8DjgVvJntm639a3qd7PANP6leX62W67lgIDPwt6VotiGQkz3H1VGH8RmBHG97u/Q+gmeD1wP/t5vUNXyjJgDXAn8Edgg7vXwiLN9WrUOczfCEwd2Yj32j8CfwWkYXoq+3d96xz4DzN7MDyfHnL+bO9Tz1OQfLm7m9l+eQ6ymY0DbgQucfdNZtaYtz/W290T4AgzmwTcDMxvcUi5MbN3AWvc/UEze2ur4xlhb3b3lWZ2AHCnmT3RPDOPz3Y7thTa7VnQq83sQIAwXBPK95u/g5kVyRLCde5+Uyje7+sN4O4bgHvIuk8mmVl9R6+5Xo06h/kTgXUjHOreeBNwspk9A/yUrAvpG+y/9W1w95VhuIYs+R9Fzp/tdkwK7fYs6FuAc8P4uWR97vXyc8IZC0cDG5uapKOGZU2C7wGPu/vXm2btt/U2s+mhhYCZdZIdQ3mcLDm8LyzWv871v8X7gLs9dDqPBu7+GXef7e5zyL6vd7v7Weyn9a0zs7FmNr4+DrwDeIS8P9utPpDSooM3JwFPkvXDfrbV8QxjvX4CrAKqZP2J55P1pd4FPAX8JzAlLGtkZ2H9EVgOLGx1/HtY5zeT9bs+DCwLr5P253oDfwL8PtT5EeB/h/JDgN8BK4CfAR2hvBymV4T5h7S6DntR97cCt7ZDfUP9HgqvR+u/VXl/tnWbCxERaWjH7iMREdkFJQUREWlQUhARkQYlBRERaVBSEBGRBiUFkRYxs7fW7/gpsq9QUhARkQYlBZGXYWZnh+cXLDOz74Sb0W0xs6vC8wzuMrPpYdkjzOy34X72Nzfd6/5QM/vP8AyEpWb238Lmx5nZDWb2hJldZ803bRJpASUFkd0ws9cAZwBvcvcjgAQ4CxgLLHH31wG/Ar4QVrkW+LS7/wnZVaX18uuAb3n2DIQ/I7vyHLK7ul5C9myPQ8ju8yPSMrpLqsjunQD8KfBA2InvJLsBWQpcH5b5F+AmM5sITHL3X4XyRcDPwv1rZrn7zQDu3gsQtvc7d+8K08vInodxX/7VEhmYkoLI7hmwyN0/s0Oh2ef7Lben94vpaxpP0HdSWkzdRyK7dxfwvnA/+/rzcV9J9t2p36Hzg8B97r4RWG9mx4byDwG/cvfNQJeZnRq20WFmY0a0FiKDpL0Skd1w98fM7HNkT7+KyO5AeyGwFTgqzFtDdtwBslsZfzv86D8NnBfKPwR8x8y+HLZx+ghWQ2TQdJdUkT1gZlvcfVyr4xAZbuo+EhGRBrUURESkQS0FERFpUFIQEZEGJQUREWlQUhARkQYlBRERafj/RiM68NxCFQUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Early Stopping\n",
    "\n",
    "- 더 이상 학습이 진행되지 않으면 traing 중간에 early stop 시킨다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checkpointing 및 Best Model save\n",
    "\n",
    "- training 작업이 길어질 경우 중간에 시스템 이상 등으로 termination 될 경우를 대비하여 그 때까지의 훈련된 weight 저장\n",
    "- checkpoint 시 저장된 weight 부터 load 하여 추가 training  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Rate Decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 학습률을 점점 줄이기 위한 함수\n",
    "def decay(epoch):\n",
    "    if epoch < 10:\n",
    "        return 1e-2  # 0.01\n",
    "    elif epoch >= 10 and epoch < 100:\n",
    "        return 1e-3   # 0.001\n",
    "    else:\n",
    "        return 1e-5   # 0.00001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 에포크가 끝날 때마다 학습률을 출력하는 콜백\n",
    "class PrintLR(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        print('\\n에포크 {}의 학습률은 {}입니다.'.format(epoch + 1, \n",
    "                                model.optimizer.lr.numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모든 Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    early_stop,\n",
    "    tf.keras.callbacks.ModelCheckpoint(\n",
    "            filepath='best_weights.hdf5', \n",
    "            save_weights_only=True,\n",
    "            monitor='val_mse',\n",
    "            save_best_only=True),\n",
    "    tf.keras.callbacks.LearningRateScheduler(decay),\n",
    "    PrintLR()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 545.3268 - mse: 545.3268WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "\n",
      "에포크 1의 학습률은 0.009999999776482582입니다.\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 372.5046 - mse: 372.5046 - val_loss: 53.7944 - val_mse: 53.7944 - lr: 0.0100\n",
      "Epoch 2/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 48.8995 - mse: 48.8995WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "\n",
      "에포크 2의 학습률은 0.009999999776482582입니다.\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 64.0184 - mse: 64.0184 - val_loss: 31.3003 - val_mse: 31.3003 - lr: 0.0100\n",
      "Epoch 3/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 28.1412 - mse: 28.1412WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "\n",
      "에포크 3의 학습률은 0.009999999776482582입니다.\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 22.5993 - mse: 22.5993 - val_loss: 21.3298 - val_mse: 21.3298 - lr: 0.0100\n",
      "Epoch 4/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 14.4380 - mse: 14.4380WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "\n",
      "에포크 4의 학습률은 0.009999999776482582입니다.\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 13.6013 - mse: 13.6013 - val_loss: 16.3126 - val_mse: 16.3126 - lr: 0.0100\n",
      "Epoch 5/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 7.0693 - mse: 7.0693WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "\n",
      "에포크 5의 학습률은 0.009999999776482582입니다.\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 11.0556 - mse: 11.0556 - val_loss: 13.8222 - val_mse: 13.8222 - lr: 0.0100\n",
      "Epoch 6/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 9.8228 - mse: 9.8228WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "\n",
      "에포크 6의 학습률은 0.009999999776482582입니다.\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 8.7741 - mse: 8.7741 - val_loss: 12.9595 - val_mse: 12.9595 - lr: 0.0100\n",
      "Epoch 7/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 7.0194 - mse: 7.0194WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "\n",
      "에포크 7의 학습률은 0.009999999776482582입니다.\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7.9825 - mse: 7.9825 - val_loss: 11.3678 - val_mse: 11.3678 - lr: 0.0100\n",
      "Epoch 8/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 4.2319 - mse: 4.2319WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "\n",
      "에포크 8의 학습률은 0.009999999776482582입니다.\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7.2958 - mse: 7.2958 - val_loss: 10.7454 - val_mse: 10.7454 - lr: 0.0100\n",
      "Epoch 9/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 12.0396 - mse: 12.0396WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "\n",
      "에포크 9의 학습률은 0.009999999776482582입니다.\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6.9205 - mse: 6.9205 - val_loss: 11.5531 - val_mse: 11.5531 - lr: 0.0100\n",
      "Epoch 10/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 4.9275 - mse: 4.9275WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "\n",
      "에포크 10의 학습률은 0.009999999776482582입니다.\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6.7204 - mse: 6.7204 - val_loss: 11.4758 - val_mse: 11.4758 - lr: 0.0100\n",
      "Epoch 11/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 3.4662 - mse: 3.4662WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "\n",
      "에포크 11의 학습률은 0.0010000000474974513입니다.\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6.4244 - mse: 6.4244 - val_loss: 11.2591 - val_mse: 11.2591 - lr: 0.0010\n",
      "Epoch 12/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 5.5142 - mse: 5.5142WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "\n",
      "에포크 12의 학습률은 0.0010000000474974513입니다.\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6.3554 - mse: 6.3554 - val_loss: 10.7138 - val_mse: 10.7138 - lr: 0.0010\n",
      "Epoch 13/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 8.4254 - mse: 8.4254WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "\n",
      "에포크 13의 학습률은 0.0010000000474974513입니다.\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6.2914 - mse: 6.2914 - val_loss: 10.5565 - val_mse: 10.5565 - lr: 0.0010\n",
      "Epoch 14/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 5.6325 - mse: 5.6325WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "\n",
      "에포크 14의 학습률은 0.0010000000474974513입니다.\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6.2714 - mse: 6.2714 - val_loss: 10.4924 - val_mse: 10.4924 - lr: 0.0010\n",
      "Epoch 15/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 3.2554 - mse: 3.2554WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "\n",
      "에포크 15의 학습률은 0.0010000000474974513입니다.\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6.2849 - mse: 6.2849 - val_loss: 10.4608 - val_mse: 10.4608 - lr: 0.0010\n",
      "Epoch 16/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 5.7568 - mse: 5.7568WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "\n",
      "에포크 16의 학습률은 0.0010000000474974513입니다.\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6.2572 - mse: 6.2572 - val_loss: 10.4346 - val_mse: 10.4346 - lr: 0.0010\n",
      "Epoch 17/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 4.0059 - mse: 4.0059WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "\n",
      "에포크 17의 학습률은 0.0010000000474974513입니다.\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6.1823 - mse: 6.1823 - val_loss: 10.7465 - val_mse: 10.7465 - lr: 0.0010\n",
      "Epoch 18/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 4.1987 - mse: 4.1987WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "\n",
      "에포크 18의 학습률은 0.0010000000474974513입니다.\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6.1875 - mse: 6.1875 - val_loss: 10.6767 - val_mse: 10.6767 - lr: 0.0010\n",
      "Epoch 19/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 4.8155 - mse: 4.8155WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "\n",
      "에포크 19의 학습률은 0.0010000000474974513입니다.\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6.2161 - mse: 6.2161 - val_loss: 10.3965 - val_mse: 10.3965 - lr: 0.0010\n",
      "Epoch 20/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 5.5545 - mse: 5.5545WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "\n",
      "에포크 20의 학습률은 0.0010000000474974513입니다.\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6.1597 - mse: 6.1597 - val_loss: 10.6868 - val_mse: 10.6868 - lr: 0.0010\n",
      "Epoch 21/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 7.1866 - mse: 7.1866WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "\n",
      "에포크 21의 학습률은 0.0010000000474974513입니다.\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6.1775 - mse: 6.1775 - val_loss: 10.6385 - val_mse: 10.6385 - lr: 0.0010\n",
      "Epoch 22/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 4.5031 - mse: 4.5031WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "\n",
      "에포크 22의 학습률은 0.0010000000474974513입니다.\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6.0712 - mse: 6.0712 - val_loss: 10.3255 - val_mse: 10.3255 - lr: 0.0010\n",
      "Epoch 23/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 7.1458 - mse: 7.1458WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "\n",
      "에포크 23의 학습률은 0.0010000000474974513입니다.\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6.1255 - mse: 6.1255 - val_loss: 10.4312 - val_mse: 10.4312 - lr: 0.0010\n",
      "Epoch 24/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 4.7303 - mse: 4.7303WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "\n",
      "에포크 24의 학습률은 0.0010000000474974513입니다.\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6.2455 - mse: 6.2455 - val_loss: 10.3460 - val_mse: 10.3460 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 6.3019 - mse: 6.3019WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "\n",
      "에포크 25의 학습률은 0.0010000000474974513입니다.\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6.1176 - mse: 6.1176 - val_loss: 10.7848 - val_mse: 10.7848 - lr: 0.0010\n",
      "Epoch 26/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 5.9126 - mse: 5.9126WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "\n",
      "에포크 26의 학습률은 0.0010000000474974513입니다.\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6.1149 - mse: 6.1149 - val_loss: 10.6862 - val_mse: 10.6862 - lr: 0.0010\n",
      "Epoch 27/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 3.3101 - mse: 3.3101WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "\n",
      "에포크 27의 학습률은 0.0010000000474974513입니다.\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6.0632 - mse: 6.0632 - val_loss: 10.4091 - val_mse: 10.4091 - lr: 0.0010\n",
      "Epoch 28/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 6.4096 - mse: 6.4096WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "\n",
      "에포크 28의 학습률은 0.0010000000474974513입니다.\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6.0346 - mse: 6.0346 - val_loss: 10.6022 - val_mse: 10.6022 - lr: 0.0010\n",
      "Epoch 29/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 3.5600 - mse: 3.5600WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "\n",
      "에포크 29의 학습률은 0.0010000000474974513입니다.\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6.0218 - mse: 6.0218 - val_loss: 10.4774 - val_mse: 10.4774 - lr: 0.0010\n",
      "Epoch 30/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 5.6093 - mse: 5.6093WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "\n",
      "에포크 30의 학습률은 0.0010000000474974513입니다.\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 5.9840 - mse: 5.9840 - val_loss: 10.2902 - val_mse: 10.2902 - lr: 0.0010\n",
      "Epoch 31/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 11.9614 - mse: 11.9614WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "\n",
      "에포크 31의 학습률은 0.0010000000474974513입니다.\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 5.9723 - mse: 5.9723 - val_loss: 10.3864 - val_mse: 10.3864 - lr: 0.0010\n",
      "Epoch 32/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 4.6443 - mse: 4.6443WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "\n",
      "에포크 32의 학습률은 0.0010000000474974513입니다.\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 5.9727 - mse: 5.9727 - val_loss: 10.4222 - val_mse: 10.4222 - lr: 0.0010\n",
      "Epoch 33/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 3.8080 - mse: 3.8080WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "\n",
      "에포크 33의 학습률은 0.0010000000474974513입니다.\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 5.9710 - mse: 5.9710 - val_loss: 10.3413 - val_mse: 10.3413 - lr: 0.0010\n",
      "Epoch 34/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 6.1117 - mse: 6.1117WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "\n",
      "에포크 34의 학습률은 0.0010000000474974513입니다.\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 5.9603 - mse: 5.9603 - val_loss: 10.4345 - val_mse: 10.4345 - lr: 0.0010\n",
      "Epoch 35/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 6.3149 - mse: 6.3149WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "\n",
      "에포크 35의 학습률은 0.0010000000474974513입니다.\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 5.9268 - mse: 5.9268 - val_loss: 10.5021 - val_mse: 10.5021 - lr: 0.0010\n",
      "Epoch 36/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 6.0302 - mse: 6.0302WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "\n",
      "에포크 36의 학습률은 0.0010000000474974513입니다.\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 5.9519 - mse: 5.9519 - val_loss: 10.6482 - val_mse: 10.6482 - lr: 0.0010\n",
      "Epoch 37/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 12.5631 - mse: 12.5631WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "\n",
      "에포크 37의 학습률은 0.0010000000474974513입니다.\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 5.9644 - mse: 5.9644 - val_loss: 10.4246 - val_mse: 10.4246 - lr: 0.0010\n",
      "Epoch 38/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 6.0048 - mse: 6.0048WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "\n",
      "에포크 38의 학습률은 0.0010000000474974513입니다.\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 5.8987 - mse: 5.8987 - val_loss: 10.3788 - val_mse: 10.3788 - lr: 0.0010\n",
      "Epoch 39/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 5.8163 - mse: 5.8163WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "\n",
      "에포크 39의 학습률은 0.0010000000474974513입니다.\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 5.9040 - mse: 5.9040 - val_loss: 10.0218 - val_mse: 10.0218 - lr: 0.0010\n",
      "Epoch 40/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 5.3539 - mse: 5.3539WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "\n",
      "에포크 40의 학습률은 0.0010000000474974513입니다.\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 5.9059 - mse: 5.9059 - val_loss: 10.3958 - val_mse: 10.3958 - lr: 0.0010\n",
      "Epoch 41/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 7.4897 - mse: 7.4897WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "\n",
      "에포크 41의 학습률은 0.0010000000474974513입니다.\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 5.9131 - mse: 5.9131 - val_loss: 10.0098 - val_mse: 10.0098 - lr: 0.0010\n",
      "Epoch 42/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 10.5104 - mse: 10.5104WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "\n",
      "에포크 42의 학습률은 0.0010000000474974513입니다.\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 5.8591 - mse: 5.8591 - val_loss: 10.0876 - val_mse: 10.0876 - lr: 0.0010\n",
      "Epoch 43/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 5.6286 - mse: 5.6286WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "\n",
      "에포크 43의 학습률은 0.0010000000474974513입니다.\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 5.8366 - mse: 5.8366 - val_loss: 10.1500 - val_mse: 10.1500 - lr: 0.0010\n",
      "Epoch 44/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 8.2506 - mse: 8.2506WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "\n",
      "에포크 44의 학습률은 0.0010000000474974513입니다.\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 5.8534 - mse: 5.8534 - val_loss: 10.4270 - val_mse: 10.4270 - lr: 0.0010\n",
      "Epoch 45/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 11.2022 - mse: 11.2022WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "\n",
      "에포크 45의 학습률은 0.0010000000474974513입니다.\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 5.8671 - mse: 5.8671 - val_loss: 10.2518 - val_mse: 10.2518 - lr: 0.0010\n",
      "Epoch 46/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 5.6657 - mse: 5.6657WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "\n",
      "에포크 46의 학습률은 0.0010000000474974513입니다.\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 5.8881 - mse: 5.8881 - val_loss: 10.6311 - val_mse: 10.6311 - lr: 0.0010\n",
      "Epoch 47/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 8.8784 - mse: 8.8784WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "\n",
      "에포크 47의 학습률은 0.0010000000474974513입니다.\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 5.8555 - mse: 5.8555 - val_loss: 10.1658 - val_mse: 10.1658 - lr: 0.0010\n",
      "Epoch 48/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 9.3482 - mse: 9.3482WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "\n",
      "에포크 48의 학습률은 0.0010000000474974513입니다.\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 5.8393 - mse: 5.8393 - val_loss: 10.0568 - val_mse: 10.0568 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 7.3383 - mse: 7.3383WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "\n",
      "에포크 49의 학습률은 0.0010000000474974513입니다.\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 5.7464 - mse: 5.7464 - val_loss: 10.1369 - val_mse: 10.1369 - lr: 0.0010\n",
      "Epoch 50/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 6.1530 - mse: 6.1530WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "\n",
      "에포크 50의 학습률은 0.0010000000474974513입니다.\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 5.8091 - mse: 5.8091 - val_loss: 10.1452 - val_mse: 10.1452 - lr: 0.0010\n",
      "Epoch 51/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 6.5430 - mse: 6.5430WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "\n",
      "에포크 51의 학습률은 0.0010000000474974513입니다.\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 5.7649 - mse: 5.7649 - val_loss: 10.2005 - val_mse: 10.2005 - lr: 0.0010\n"
     ]
    }
   ],
   "source": [
    "model = build_model()\n",
    "\n",
    "history = model.fit(train_ds, epochs=500, validation_data=test_ds, verbose=1, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 저장된 best weight 를 load 하여 사용\n",
    "\n",
    "model.load_weights( ) method 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model()\n",
    "\n",
    "model.load_weights('best_weights.hdf5')\n",
    "\n",
    "model.compile(loss='mse', optimizer='adam', metrics=['mae', 'mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(98, 9)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[31.089216]], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test[0].reshape(1, 9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32.9"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
